---
title: Investor Pitch
subtitle: getdelv â€” Coding Docs for Machines
date: 2025-03-12 
author: Lukas
---


[getdelv.com](https://getdelv.com) 
[lukas@getdelv.com](mailto:lukas@getdelv.com)

## Executive Summary
getdelv is a queryable data source for LLMs that generate code. The LLM queries the delv database for documentation that may have changed recently or that is too obscure to be retained in its weights. Our aim is to be the link between disparate data sources and the LLM.

getdelv is distinct from an internet search engine in that:
- It only indexes coding related webpages, so it's faster and cheaper to run, and more capable.
- It returns a paragraph or two of text that can be directly inserted into the model context, as opposed to a list of links.
- It can be tuned to work with a specific tech stack or problem domain, which reduces noise and improves quality.
- We index code pages extremely well, providing high-quality results that make integrating SaaS APIs much easier.

Here is a demo showing how our product integrates with Claude desktop to improve coding performance:
<!-- Responsive video container -->
<div style="position: relative; width: 100%; height: 0; padding-bottom: 56.25%;">
  <!-- YouTube embed -->
  <iframe
    src="https://www.youtube-nocookie.com/embed/2E3lmYhaqb0?vq=hd1080p"
    title="YouTube video player"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    referrerpolicy="strict-origin-when-cross-origin"
    allowfullscreen
    style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
  </iframe>
</div>

We have launched a closed beta to a small group of early testers, with a public launch planned for May 2025.

<hr style="height: 4px; background-color: black; border: none;">

## Market Opportunity

Search was never practical until now because it required indexing the entire internet to make a general search engine. Since the advent of LLMs we now have a new use case for search engines - code specific search for LLMs working on code generation.

Current AI coding systems face the following limitations:
- Models are very large and expensive to run because they store data in their weights
- API references, bug reports, and documentation change daily, making models quickly outdated
- Obscure information isn't retained in training even by the biggest models

Existing search engines don't adequately address this problem because:
- Additional tooling is required to make them integrate well with applications/agents such as MCP servers etc
- They prioritize user-friendly websites with ads over information-dense results
- They return long lists of links rather than the concise paragraphs of text that models need
- They're expensive and slow because they index the entire internet

The current challenge is identifying ideas that benefit from AI growth without:
- Competing against big AI labs
- Being a thin wrapper around a model
- Being undermined by future advancements in AI

We are ideally positioned because:
- Growth in LLM usage directly benefits us
- Recent hardware and software improvements make it feasible to build a search engine with a shoestring budget and small team
- AI tooling is taking off (MCP servers, Agents etc.)

<hr style="height: 4px; background-color: black; border: none;">

## Our Users and Revenue Model

Our target customers are companies building AI agents and AI-powered software, including:
- Code assistants (GitHub Copilot, Cursor, Tabnine, Codeium)
- AI-powered development platforms (Replit, Lovable)
- Internal developer tooling teams

We will charge these companies a fee to access our database via API for enterprise usage, while making it free for individual developers to increase adoption.

We are currently reaching out to these companies in order to validate our thesis.

<hr style="height: 4px; background-color: black; border: none;">

## Competition
- **Brave Search API**: Provides general-purpose search and returns lists of links. Used by Mistral, Perplexity, Cohere, and others.
- **Exa.ai**: Modern AI-first search platform focused on querying the internet like a database, used for generating datasets like sales prospects.
- **Perplexity**: Returns text generated by an LLM on the fly, but is expensive and slow.
- **Tavily**: Search API designed for use with LLMs. New entrant.

### Our Competitive Advantage
Our unique advantage stems from our specialized focus on coding:

- **Optimized Processing**: Due to the smaller number of pages we index, we can pre-process and store cleaned, curated text results in our database. This allows us to return high-quality text very quickly, an approach that's unfeasible for general search APIs.

- **Cost Efficiency**: Our specialized coding search covers less than 1% of internet pages, dramatically reducing storage, bandwidth, and compute costs.

- **Superior Performance**: Our focused index enables us to use algorithms that would be impractical for full-scale search engines. We can afford to process every page through an LLM to generate high-quality metadata, yielding much better results for coding queries.

<hr style="height: 4px; background-color: black; border: none;">

## Progress and Timelines
**Jan and Feb 2025**: Initial idea, iteration. 
**March 2025**: Full time work on MVP commences.
**Mid March 2025**: We are reaching out to potential customers in order to validate our idea. 

The public MVP is tentatively planned for May 2025.

<hr style="height: 4px; background-color: black; border: none;">

## Technical

Indexing the entire internet is extremely challenging and expensive. Our approach is to incrementally add data to our index, and strictly curate the data sources we add. Our MVP will not rely only on our own search index, but rather on one from a commercial provider. Over time, we will scale to building our own, as follows:

The data will be sourced by scraping a curated list of sites, and slowly branching out from there. We will use a classifier to only follow links to new pages that are relevant to our initial focus. We can also add data directly from SaaS providers. Initially we will only index sites relevant to a particular tech stack. This keeps the amount of data we need to handle reasonable, and we wont need to rely on complex distributed systems.

In order to be able to return text results we need to clean the raw html. This can be achieved with a mix of heuristics (discarding footers etc.) as well as with LLMs. This isn't feasible to do with an internet-wide search engine. One key advantage we have over competitors is that we can create a suit of parsers designed for common code-related sites such as GitHub, which allows us to extract the relevant content of various pages at low cost. 

The search itself will initially be done using open source search engine software. As we scale we can consider using a more modern approach, where we use LLMs to generate metadata and vector representations of each page.

Modern servers can have hundreds of cores and TBs of RAM. We will do everything we can to make our software run on a single node, which removes a lot of the complexity that used to exist in creating these types of systems. Additionally many tasks that historically would have been run on CPU can now be run on GPU. For instance by parsing web pages with LLMs or ranking pages using a NN running on GPU. Due to all the focus on using GPUs for training LLMs, it's getting easier and easier to process large volumes of data with them using open source software.

<hr style="height: 4px; background-color: black; border: none;">

## Founder

I previously worked as an ML engineer, building data pipelines, training models, and deploying them to production. The company I worked for specializes in creating recommendation systems for books by analyzing their content using ML models. I received an Emergent Ventures grant from Tyler Cowen for my work with LLMs. My academic background is in biochemistry and microbiology, and I served in the military, passing paratrooper selection and serving on active duty. I'm a competitive amateur athlete and won bronze at nationals.

## Contact
[getdelv.com](https://getdelv.com)
[lukas@getdelv.com](mailto:lukas@getdelv.com)
[LinkedIn](https://www.linkedin.com/in/lukas-bogacz/)