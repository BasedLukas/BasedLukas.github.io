<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lukas&#39;s Writings</title>
  
  
  <link href="http://loreley.one/atom.xml" rel="self"/>
  
  <link href="http://loreley.one/"/>
  <updated>2025-03-31T21:57:49.756Z</updated>
  <id>http://loreley.one/</id>
  
  <author>
    <name>Lukas</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>WASM</title>
    <link href="http://loreley.one/2024-12-wasm/"/>
    <id>http://loreley.one/2024-12-wasm/</id>
    <published>2024-12-06T23:00:00.000Z</published>
    <updated>2025-03-31T21:57:49.756Z</updated>
    
    <content type="html"><![CDATA[ <style>     /* Default: hide the iframe and show the message for mobile portrait mode */     #robot-frame {         display: none;     }     #mobile-message {         display: none;         font-size: 1.5em;         text-align: center;         color: red;         font-weight: bold;         margin-top: 50px;     }     /* Show the iframe on landscape mode */     @media screen and (orientation: landscape) and (max-width: 768px) {         #robot-frame {             display: block;         }         #mobile-message {             display: none;         }     }     /* Show the iframe for desktops */     @media screen and (min-width: 769px) {         #robot-frame {             display: block;         }         #mobile-message {             display: none;         }     } </style>  <!-- The iframe --> <iframe id="robot-frame" src="robot.html" style="width: 100%; height: 850px; border: none;"></iframe> <!-- Message for mobile portrait mode --> <div id="mobile-message">     The game cannot load in portrait mode. <br>      Please turn your phone sideways or visit on a desktop device. </div><script>    // JavaScript to handle dynamic behavior    function handleOrientationChange() {        const iframe = document.getElementById('robot-frame');        const message = document.getElementById('mobile-message');        if (window.innerWidth < 769) {            if (window.matchMedia("(orientation: landscape)").matches) {                iframe.style.display = "block";                message.style.display = "none";            } else {                iframe.style.display = "none";                message.style.display = "block";            }        } else {            iframe.style.display = "block"; // Desktop always shows            message.style.display = "none";        }    }    // Initial check    handleOrientationChange();    // Listen for orientation changes    window.addEventListener('resize', handleOrientationChange);</script><p><em>Note: This puzzle is based on a <a href="https://loreley.one/2023-07-cpu/">previous blog post </a> of mine. I’ve reprinted it below (with slight modifications) to provide the context of how this CPU works and why I made it. The functionality of the CPU is derived entirely from simulated logic gates. All the operations and control flow are based on the underlying properties of the logic gates, and changing their operation leads to corresponding changes in function.</em><br><em>I’ve been playing around with WASM (Web Assembly) and decided to resuscitate my old python code from that blogpost in order to run it in the browser. The entire python interpreter is bundled with the game code using WASM in the browser. I thought this was pretty cool.</em><br><em>Thanks to Ivan for reviewing an earlier version of this post.</em></p><button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#tutorial" aria-expanded="false" aria-controls="collapse">Tutorial</button><button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#old-cpu-post" aria-expanded="false" aria-controls="collapse">Old Blog Post</button><div class="collapse" id="tutorial"><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>This CPU features six general-purpose registers (<code>reg0</code> to <code>reg5</code>), along with a special register (<code>reg6</code>) used for both input and output. It supports four main types of operations:</p><ul><li><strong>Immediate Values</strong></li><li><strong>Arithmetic Operations</strong></li><li><strong>Copying</strong></li><li><strong>Comparisons and Control Flow</strong></li></ul><p>All values in the CPU are 8-bit and overflow after 255 to 0.<br>For comparisons, values are treated as <strong>signed</strong> (range -128 to 127).</p><hr><h3 id="Immediate-Values"><a href="#Immediate-Values" class="headerlink" title="Immediate Values"></a>Immediate Values</h3><p>Load a constant value into <code>reg0</code>. Only values up to 63 are allowed because the two most significant bits (MSB) are reserved for instruction encoding.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0       # Load 0 into reg0 (min allowed immediate)</span><br><span class="line">36      # Load 36 into reg0</span><br><span class="line">63      # Load 63 into reg0 (max allowed immediate)</span><br></pre></td></tr></table></figure><hr><h3 id="Copying-Data"><a href="#Copying-Data" class="headerlink" title="Copying Data"></a>Copying Data</h3><p>The <code>copy</code> instruction copies data between registers or between a register and the input&#x2F;output.<br><strong>Input and Output</strong>: <code>reg6</code> serves as both the input and output register.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">copy &lt;source_register&gt; &lt;destination_register&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">copy 6 1   # Copy value from input (reg6) to reg1</span><br><span class="line">copy 3 6   # Copy value from reg3 to output (reg6)</span><br><span class="line">copy 5 3   # Copy value from reg5 into reg3</span><br><span class="line">copy 6 6   # Copy from input directly to output</span><br><span class="line">copy 1 1   # NOP</span><br></pre></td></tr></table></figure><hr><h3 id="Arithmetic-and-Logical-Operations"><a href="#Arithmetic-and-Logical-Operations" class="headerlink" title="Arithmetic and Logical Operations"></a>Arithmetic and Logical Operations</h3><p>Arithmetic and logical operations use <code>reg1</code> and <code>reg2</code> as operands and store the result in <code>reg3</code>.<br>Arithmetic uses 2’s complliment. Values overflow if they exceed 255. </p><p><strong>Addition</strong> (<code>add</code>): Adds <code>reg1</code> and <code>reg2</code>.<br><strong>Subtraction</strong> (<code>sub</code>): Subtracts <code>reg2</code> from <code>reg1</code>.<br><strong>Bitwise AND</strong> (<code>and</code>): Performs a bitwise AND operation on <code>reg1</code> and <code>reg2</code>.<br><strong>Bitwise OR</strong> (<code>or</code>): Performs a bitwise OR operation on <code>reg1</code> and <code>reg2</code>.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1        # Load 1 into reg0</span><br><span class="line">copy 0 1 # Move 1 into reg1</span><br><span class="line">2        # Load 2 into reg0</span><br><span class="line">copy 0 2 # Move 2 into reg2</span><br><span class="line">add      # reg3 = reg1 + reg2 = 1 + 2 = 3</span><br><span class="line">copy 3 6 # Output result (3)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">32</span><br><span class="line">copy 0 1</span><br><span class="line">32</span><br><span class="line">copy 0 2</span><br><span class="line">add  # 64 in reg 3</span><br><span class="line">copy 3 2</span><br><span class="line">copy 3 1</span><br><span class="line">add # 128 in reg 3</span><br><span class="line">copy 3 1</span><br><span class="line">copy 3 2</span><br><span class="line">add </span><br><span class="line">copy 3 6</span><br><span class="line"># total 256, so output is 0 == [0,0,0,0,0,0,0,0]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0</span><br><span class="line">copy 0 1</span><br><span class="line">2</span><br><span class="line">copy 0 2</span><br><span class="line">sub  # 0 - 2 = -2</span><br><span class="line">copy 3 6</span><br><span class="line"># cpu output is -2 == [1,1,1,1,1,1,1,0]</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">32</span><br><span class="line">copy 0 1</span><br><span class="line">32</span><br><span class="line">copy 0 2</span><br><span class="line">add  # 64 in reg 3</span><br><span class="line">copy 3 2</span><br><span class="line">copy 3 1</span><br><span class="line">add # 128 in reg 3</span><br><span class="line">1</span><br><span class="line">copy 0 2</span><br><span class="line">copy 3 1</span><br><span class="line">sub     # 128 - 1</span><br><span class="line">copy 3 6</span><br><span class="line"># result is 127 == [0,1,1,1,1,1,1,1] in 2&#x27;s compliment</span><br></pre></td></tr></table></figure><hr><h3 id="Comparisons-and-Control-Flow"><a href="#Comparisons-and-Control-Flow" class="headerlink" title="Comparisons and Control Flow"></a>Comparisons and Control Flow</h3><p>The <code>eval</code> instruction compares the <strong>signed</strong> value in <code>reg3</code> against <code>0</code>. If the condition is true, the program counter jumps to the address in <code>reg0</code>.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">eval &lt;condition&gt;</span><br></pre></td></tr></table></figure><p>Supported conditions:</p><ul><li><code>eval always</code>: Always jump.</li><li><code>eval never</code>: Never jump.</li><li><code>eval =</code>: Jump if <code>reg3 == 0</code>.</li><li><code>eval !=</code>: Jump if <code>reg3 != 0</code>.</li><li><code>eval &lt;</code>: Jump if <code>reg3 &lt; 0</code> (signed).</li><li><code>eval &lt;=</code>: Jump if <code>reg3 &lt;= 0</code> (signed).</li><li><code>eval &gt;</code>: Jump if <code>reg3 &gt; 0</code> (signed).</li><li><code>eval &gt;=</code>: Jump if <code>reg3 &gt;= 0</code> (signed).</li></ul><hr><h3 id="Labels"><a href="#Labels" class="headerlink" title="Labels"></a>Labels</h3><p>Labels act as named locations in the program. Defining a label associates it with its position in the program. Calling labels is just shorthand for using immediate values (and thus labels can’t be placed after line 63).</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">label &lt;name&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">label start # start = 0</span><br><span class="line">copy 6 1    # Read input into reg1</span><br><span class="line">add         # Add reg1 and reg2</span><br><span class="line">start       # Label used here as jump target, equvalent to using immediate 0</span><br><span class="line">eval &gt;=     # Jump to &quot;start&quot; if reg3 &gt;= 0</span><br></pre></td></tr></table></figure><p>This program copies <code>1</code> into <code>reg1</code>, adds it with <code>reg2</code>, and stores the result in <code>reg2</code> in a loop until the result overflows and becomes negative.</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1           # Load 1 into reg0</span><br><span class="line">copy 0 1    # Copy 1 into reg1</span><br><span class="line">label loop</span><br><span class="line">add         # reg3 = reg1 + reg2</span><br><span class="line">copy 3 2    # Store result in reg2</span><br><span class="line">copy 3 6    # print result to output</span><br><span class="line">loop</span><br><span class="line">eval &gt;=     # Jump to label loop if reg3 &gt;= 0</span><br></pre></td></tr></table></figure><p><strong>For comparisons, the value is treated as signed (<code>127</code> is interpreted as <code>127</code>, but <code>128</code> is interpreted as <code>-128</code>). The last result the cpu prints is thus <code>128</code></strong></p><h3 id="Robot-Instructions"><a href="#Robot-Instructions" class="headerlink" title="Robot Instructions"></a>Robot Instructions</h3><p>output (controls):<br><code>1 == turn left</code><br><code>2 == turn right</code><br><code>3 == step forward</code></p><p>input:<br><code>1 == wall</code><br><code>0 == clear</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># this will rotate you left</span><br><span class="line">1</span><br><span class="line">copy 0 6</span><br><span class="line"></span><br><span class="line"># rotate right 3 times</span><br><span class="line">2</span><br><span class="line">copy 0 6</span><br><span class="line">copy 0 6</span><br><span class="line">copy 0 6</span><br><span class="line"></span><br><span class="line"># walk in a line until blocked</span><br><span class="line">label start_loop</span><br><span class="line">3</span><br><span class="line">copy 0 6</span><br><span class="line">copy 6 3    # put the input in reg3</span><br><span class="line">start_loop</span><br><span class="line">eval =      # if reg3 is 0 there is no wall</span><br></pre></td></tr></table></figure><p>glhf</p><button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#tutorial" aria-expanded="false" aria-controls="collapse">Hide Tutorial</button></div><div id="old-cpu-post" class="collapse"><h2 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h2><p>A while back, I came across an interesting game on Steam called <a href="https://turingcomplete.game/">Turing Complete</a>. The objective of the game is to design a Turing complete CPU from scratch, and it guides players through each step of the process. Starting with the basics of logic gates, the building blocks of a CPU, players tackle progressively more complex challenges until they reach the point of designing their own CPU capable of performing simple tasks. I found the game captivating and spent an unhealthy amount of time in it.</p><center><img src="turing_complete.jpg" alt="turing_complete"><p><small>Turing Complete gameplay</small></p></center><p>After completing the game, I decided it would be fun to create a Python emulator for a similar CPU. While it’s relatively easy to make a basic emulator in Python due to its high-level nature, I chose a different approach. I wanted to build the CPU entirely from scratch, deriving the logic from the fundamental functionality of logic gates. This means that the CPU’s performance is determined solely by simple true&#x2F;false comparisons, without relying on if statements or other control flows. It does make the code a bit harder to read at times, but by merely changing the function of a single logic gate, you can witness how the entire CPU’s behavior is affected (spoiler alert: it stops working).</p><h2 id="Logic-Gates"><a href="#Logic-Gates" class="headerlink" title="Logic Gates"></a>Logic Gates</h2><p>The design starts with the logic gates. Here is an excerpt of the code</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">and_</span>(<span class="params">*args:<span class="built_in">bool</span></span>)-&gt;<span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">all</span>(args))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">or_</span>(<span class="params">*args:<span class="built_in">bool</span></span>)-&gt;<span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">any</span>(args))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">not_</span>(<span class="params">*args:<span class="built_in">bool</span></span>)-&gt;<span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(<span class="keyword">not</span> <span class="built_in">all</span>(args))</span><br></pre></td></tr></table></figure><p>The logic gates perform simple comparisons and return true or false values. For example the AND gate returns true only if both of its inputs are true. The OR gate returns true if either (or both) of its inputs are true.</p><center><img src="logic_gates.jpg" alt="logic gates"><p><small>logic gate symbols</small></p></center><h2 id="Basic-Components"><a href="#Basic-Components" class="headerlink" title="Basic Components"></a>Basic Components</h2><p>Once we have our logic gates, we can utilize them to create essential components. Let’s focus on the full adder as an example. The purpose of a full adder is to take two binary inputs and perform addition on them. For instance, when adding 0 + 0, the output is 0. When adding 1 + 0, the output is 1.</p><p>However, adding 1 + 1 poses a challenge. In binary, we lack a way to represent the number 2 directly. To address this, we introduce a carry bit, similar to carrying over a digit when adding two decimal numbers that exceed 9. Additionally, we have a carry input to account for any carry bits from previous additions. </p><center><img src="full_adder.png" alt="full adder"><p><small>full adder design</small></p></center><p>A truth table is a structured table that presents the outputs corresponding to all possible input combinations. It allows us to systematically analyze the behavior of a component or system under consideration. In the case of a full adder, the truth table would display the sum output and carry output for each potential combination of binary inputs and carry input. By checking the truth table, we can see how the full adder operates under different input scenarios.</p><center><img src="full_adder_truth.png" alt="full adder truth table"><p><small>full adder truth table</small></p></center><p>The above design can now be implemented in code, using the logic gates we have created previously. In this case I first made a half adder (which doesn’t have a carry in) and used two of them to construct a full adder. Notice how all the logic is dependent on the operation of the logic gates.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">half_adder</span>(<span class="params">input1:<span class="built_in">bool</span>, input2:<span class="built_in">bool</span></span>):</span><br><span class="line">    <span class="keyword">return</span> sn(</span><br><span class="line">        <span class="built_in">sum</span>=xor(input1, input2),</span><br><span class="line">        carry=and_(input1, input2)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">full_adder</span>(<span class="params">input1:<span class="built_in">bool</span>, input2:<span class="built_in">bool</span>, carry_in:<span class="built_in">bool</span></span>):</span><br><span class="line">    half_adder1 = half_adder(input1, input2)</span><br><span class="line">    half_adder2 = half_adder(half_adder1.<span class="built_in">sum</span>, carry_in)</span><br><span class="line">    out = sn(</span><br><span class="line">        <span class="built_in">sum</span>=half_adder2.<span class="built_in">sum</span>,</span><br><span class="line">        carry=or_(half_adder1.carry, half_adder2.carry)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>After creating a number of basic components such as these, we create more complex components such as an ALU (Arithmetic Logic Unit). The task of the ALU is to perform simple mathematical operations, such as adding 2 numbers together. In this case the ALU can only perform 4 simple operations; Addition, Subtraction, and two logical operations AND and OR. I took inspiration from this 32 bit ALU design, although mine only has 8 bits.</p><center><img src="ALU.png" alt="alu"><p><small>32 bit ALU design</small></p></center><h1 id="The-Full-CPU"><a href="#The-Full-CPU" class="headerlink" title="The Full CPU"></a>The Full CPU</h1><p>The design of the CPU includes six registers, an input, and an output, along with an ALU. Additionally, there is a unit that can carry out comparisons between a value and zero. The CPU operates by executing one of four distinct types of operations:</p><ul><li><p>Immediate: This operation is for moving a given value into register 0. </p></li><li><p>Arithmetic: The operands for any arithmetic operation are always register 1 and register 2, and the resultant output is stored in register 3.</p></li><li><p>Copy: This operation is used for duplicating values from one register to another or to the output. For example, ‘copy 0 6’ copies from register 0 to the output, and ‘copy 5 3’ copies from register 5 to register 3.</p></li><li><p>Evaluation: This operation evaluates the value in register 3 against zero. If the condition is true, it sets the program counter to the value in register 0.</p></li></ul><center><img src="full_cpu.jpeg" alt="full cpu"><p><small>CPU design</small></p></center><p>Using just these operations we have already created a turing complete CPU! However writing code for it would be challenging as we would have to write everything in binary. To solve this I made a simple assembler that converts assembly code to binary. It also adds a number of useful features such as labels. Labels allow you to mark a point in your program to jump to, making it much easier to create loops in your code. Let’s take a look at a simple program. </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># create a marker at the beginning of the program where we can jump to</span><br><span class="line">label start </span><br><span class="line"></span><br><span class="line"># read from input (reg6) into reg1</span><br><span class="line">copy 6 1</span><br><span class="line"></span><br><span class="line"># add reg 1 and 2, store the result in reg3</span><br><span class="line">add</span><br><span class="line"></span><br><span class="line">#copy result from reg3 into reg2</span><br><span class="line">copy 3 2</span><br><span class="line"></span><br><span class="line"># loop back to start if the value is not negative</span><br><span class="line">start</span><br><span class="line">eval &gt;=</span><br><span class="line"></span><br><span class="line"># Once the value overflows and becomes negative send the result to the output</span><br><span class="line">copy 3 6</span><br></pre></td></tr></table></figure><p>In the simple program above, the value 1 is continuously being fed into the CPU. At each iteration we add it to the value stored in register 2, so that we increment the value by 1. Eventually the value grows large enough that it overflows and becomes negative. This is because in binary the most significant bit (MSB) is used to represent negative numbers. Once this happens the program stops running.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><center><img src="norway.jpeg" alt="NORway"><p><small>NOR-way</small></p></center><p>I thought this was quite a fun project, I certainly learnt a lot. While it may seem a little complicated, the truth is that by playing Turing Complete, you learn in a very intuitive manner. I can highly recommend it. If you want to write your own program or take a look at the code, it is all available on my <a href="https://github.com/BasedLukas/cpu_simulator">github</a>.</p><button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#old-cpu-post" aria-expanded="false" aria-controls="collapse">Hide Blog Post</button></div>]]></content>
    
    
      
      
        
        
    <summary type="html"></summary>
        
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Book Review: Unraveling Principal Component Analysis</title>
    <link href="http://loreley.one/2024-09-pca/"/>
    <id>http://loreley.one/2024-09-pca/</id>
    <published>2024-09-08T22:00:00.000Z</published>
    <updated>2025-03-31T21:57:49.723Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intuition-and-Motivation"><a href="#Intuition-and-Motivation" class="headerlink" title="Intuition and Motivation"></a>Intuition and Motivation</h2><p>Out of everything I’ve read, one of the pieces that resonated most with me was Lockhart’s Lament. Lockhart, a mathematician, published this work around 20 years ago, critiquing the way mathematics is typically taught to students. The gist of his argument is that too much emphasis is placed on memorization, notation, formulae and dry proofs. Instead he argues we should teach students to appreciate mathematics first and foremost - which can later be followed by formalism. A brilliant example:</p><blockquote style="text-align: left" >Lets take the case of a triangle inside a semicircle<br></br><center><img src="angle1.png" alt=""></center><br></br>Now the beautiful truth about this pattern is that no matter where on the circle you place thetip of the triangle, it always forms a nice right angle. (…)<br></br><center><img src="angle2.png" alt=""></center><br></br>Here is a case where our intuition is somewhat in doubt. It’s not at all clear that this shouldbe true; it even seems unlikely— shouldn’t the angle change if I move the tip? What we havehere is a fantastic math problem! Is it true? If so, why is it true? What a great project! What aterrific opportunity to exercise one’s ingenuity and imagination! Of course no such opportunity is given to the students, whose curiosity and interest is immediately deflated by:<br></br><center><img src="angle3.png" alt=""></center><br></br>Could anything be more unattractive and inelegant? Could any argument be moreobfuscatory and unreadable? This isn’t mathematics! <strong>A proof should be an epiphany from the Gods, not a coded message from the Pentagon</strong> (emphahsis added). This is what comes from a misplaced sense of logical rigor: ugliness. The spirit of the argument has been buried under a heap of confusing formalism.No mathematician works this way. No mathematician has ever worked this way. This is acomplete and utter misunderstanding of the mathematical enterprise. Mathematics is not about erecting barriers between ourselves and our intuition, and making simple things complicated. Mathematics is about removing obstacles to our intuition, and keeping simple things simple. Compare this unappetizing mess of a proof with the following argument devised by one of my seventh-graders:<br></br>“Take the triangle and rotate it around so it makes a four-sided box inside the circle. Since the triangle got turnedcompletely around, the sides of the box must be parallel,so it makes a parallelogram. But it can’t be a slanted boxbecause both of its diagonals are diameters of the circle, sothey’re equal, which means it must be an actual rectangle.That’s why the corner is always a right angle.”<br></br><center><img src="angle4.png" alt=""></center><br></br>(…) I was able to point out several stylistic and logicalproblems, and the student was then able to improve the argument. For instance, I wasn’tcompletely happy with the bit about both diagonals being diameters— I didn’t think that wasentirely obvious— but that only meant there was more to think about and more understanding tobe gained from the situation. And in fact the student was able to fill in this gap quite nicely:<p>“Since the triangle got rotated halfway around the circle, the tip<br>must end up exactly opposite from where it started. That’s why<br>the diagonal of the box is a diameter.”</p></blockquote>I felt his argument deeply. As a highschool student I was completely uninterested in “math”. University only reinforced this in me - studying for exams was an exercise in memorization combined with very basic stepwise logical reasoning. There was never any reason to do the math - it was just a constant that existed.<p>Fast forward a few years and I became interested in statistical learning. The ideas involved invite you to think intuitively. You can visualize what happens when you overfit a data set. You can intuit why your residuals should be normally distributed. You can think of gradient descent as traversing a 3D surface with local and global minima. Suddenly there was a reason to “do math”. Excited by this discovery, I decided to revisit everything I had learnt (and forgotten) at university. Armed with heaps of motivation, I bought the acclaimed “Linear Algebra Done Right”. A bulwark. A classic. Used by students all over the world. I slogged through the early chapters. It was rather dull, one definition after another. It is not difficult to follow the logic, and to see how one theorem follows from another. But the entire enterprise was draining and unfulfilling. It felt random. “Follow these steps and you get the result you are looking for. I can prove that it works because of the following …”. But <strong>why</strong> does it work? What possessed you to follow this path as opposed to any other? How might I have come up with this myself? The book provided no answers and I was left feeling deeply unsatisfied.</p><p>Fortunately, I stumbled across Unravelling Principal Component Analysis by Peter Bloem. Right from the get go it’s clear that this isn’t a textbook. This book is for:</p><blockquote style="text-align: left">People who have learned linear algebra and then forgotten it. Who feel a measure of regret that they didn’t pay full attention the first time around. If you’ve ever marveled at the magical results that PCA produces, and you’d like to really understand it, all the way down to the fundament, then this book will provide you with a guide. But perhaps it’s best to think of this as a guided tour of the forests of linear algebra.</blockquote><p>This book is an opportunity to start afresh. At no point does it feel like reading an encyclopedia. Instead it is one big intuition building exercise. We learn why each step is necessary and are left feeling we could have come up with it ourselves.</p><h2 id="Understanding-First"><a href="#Understanding-First" class="headerlink" title="Understanding First"></a>Understanding First</h2><p>Another gripe I have with math education is the order in which the material is presented. The typical textbook seems designed to confuse - leading with notation, discussing edge cases, and rarely pausing to explain. This book is structured differently. First each definition is patiently motivated, explained, then expanded upon, and finally followed by notation and formalization. The explanation of eigenvectors is a case in point:</p><blockquote style="text-align: left">The most common, and probably the most intuitive way to think about matrices is as transformations of points in space. If we have some vector x and we multiply it by a matrix A, we get a new point y = Ax. If A is square, then x and y are in the same space. A good way to visualize this is by domain coloring. We take a large number of points, arranged in a grid, and we color them by some image. This could be a simple color gradient, but we can also choose a photograph or some other image. Following Wikipedia’s example, we’ll use a picture of the Mona Lisa.<br></br><center><img src="lisa1.png" alt="An increasingly fine-grained domain coloring using the Mona Lisa."><p><small>An increasingly fine-grained domain coloring using the Mona Lisa.</small></p></center><br></br>If we apply the transformation A to each of these points, we can tell what effect the matrix has on this space.<br></br><center><img src="lisa2.png" alt=""></center><br></br>All the points are mapped to a new position by A and poor Lisa ends up squished and stretched in various directions. Transformations expressible in a matrix are linear transformations. These are the transformations for which a line in the original image is still a line in the transformed image. This means that we can rotate, stretch, squish and flip the image in any direction we like, but we can’t warp, bend or tear it.In this language of transformation, we can very naturally define what eigenvectors are. The eigenvectors of a square matrix A are defined as those vectors (i.e. points in the image) for which the direction doesn’t change under transformation by A.It’s simplest to see what this looks like for a diagonal matrix. For instance in the transformation<br></br> <div style="text-align:center;">   <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">y</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{y} = \begin{pmatrix} 2 &amp; 0 \\ 0 &amp; \frac{1}{2} \end{pmatrix} \mathbf{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4051em;vertical-align:-0.9526em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4526em;"><span style="top:-3.6126em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-2.4074em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9526em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4526em;"><span style="top:-3.6126em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">0</span></span></span><span style="top:-2.4074em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9526em;"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf">x</span></span></span></span> </div><br></br>the matrix acts independently on the first and second dimensions, squishing one, and stretching the other.<br></br><center><img src="lisa3.png" alt=""></center><br></br>In this image we’ve also drawn two vectors: one to the middle of Mona Lisa’s left eye, and one to middle of the right. Since Leonardo put the right eye dead center in the painting (not by accident, I imagine), the red vector shrinks, but doesn’t change direction. The green vector is affected by both the squishing and the stretching, so its direction and magnitude both change. Hence, the red vector is an eigenvector, and the green vector isn’t. In a diagonal matrix, the eigenvectors are always the vectors that point in the same directions as the axes, so they’re easy to identify. In general square matrices, finding the eigenvectors is more tricky.</blockquote>After first giving us this intuitive, geometric (and color coded) explanation Peter takes us to the definition.<br></br><blockquote style="text-align: left">Formally, a vector v is an eigenvector of A if the following holds for some scalar λ:<p>Av &#x3D; λv</p><p>This is just a symbolic version of what we said in words above: if v is an eigenvector of A, then transforming it changes its magnitude but not its direction, which is the same as saying we can multiply it by a scalar instead of by a matrix. The scalar corresponding to the eigenvector, in this case λ is called an eigenvalue of the matrix.</p></blockquote>and assures us:<br></br><blockquote style="text-align: left">It’s not at all clear from the definition why these vectors should be meaningful or special. For now, just trust me that eigenvectors are worth knowing about.</blockquote>This is what I love about his style. Commonly we would start by reading a list of rules, likely irrelevant to understanding the core of the concept. Mathematicians can’t refrain from interjecting. ”This only applies to finite fields and real numbers”. But why lead with that? The reader is still struggling to grasp the new concept. You are overloading their poor brain before they even have a chance to get started.<p>I believe this is partially what makes learning new math difficult - having to actively refresh what each definition in a statement means in order to understand the full statement. It takes time to build automaticity - instant, effortless understanding of a concept. When an author provides a number of definitions and rules and then immediately proceeds to build upon them he does the reader a disservice. It takes working with an idea, until the definitions and concepts become second nature. An author should strive to reduce the cognitive load on the reader. We know you are smart, you don’t have to prove it. Gently introduce the idea, keeping it to the bare minimum. Later you can write all the notation you want. Knock yourself out! Yes, I would like to know how we can prove it. Maybe I even care about the case where a vector is a zero vector, or where we are dealing with imaginary numbers. But not right now! Start with the explanation.</p><h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><p>Only the first 2 chapters actually deal with PCA. We start by examining the problem. Why do we need to reduce the dimensionality of our data? What is a principal component and why is it useful? Then we move on to understanding the basic process. How do we arrive at the solution, where do the principal components come from?<br>At this point you could stop and use the PCA implementation from your library in ignorant bliss. But that’s not actually what this book is about. It is a tour of linear algebra, hiding under the guise of PCA. If you stick with it you’ll be taken deeper. The spectral theorem, determinants and the singular value decomposition are all given the same treatment.<br>It isn’t perfect, and mathematicians will probably complain about rigor. I get it. In my opinion the dynamic runs as follows: Math is hard and requires a modicum of intelligence. This leads to a search for shortcuts to avoid the most difficult parts. So mathematicians are rightly suspect when someone comes along claiming to teach “subjective” or “intuitive” math without the rigor. In fact, any time you come across math without rigor and notation you would do well to ask why. But this book is not an attempt to avoid hard work. It’s here to satisfy your curiosity and that unease you feel when you don’t quite understand why something works as well as it does.<br>A feature of this style is that at times it can be a little hard to follow. It’s easy to follow a logical proof step by step and verify its validity. Due to the narrative style of this book it can sometimes be a little unclear exactly what is happening. But Peter acquits himself remarkably well in this regard. For the most part rereading a paragraph will be sufficient. There were however a number of times where despite rereading a section I still couldn’t make sense of it and was forced to find some other source to help me understand.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>I’m pleased to have found this book, it’s been a game changer for me. A friend recommended his <a href="https://peterbloem.nl/blog/">blog</a> to me when I was looking for explanations of the transformer architecture, which is how I found it. The full book is available on his blog as a <a href="https://peterbloem.nl/publications/unraveling-pca">free PDF</a>, or you can buy it on amazon. Lockhart’s Lament is also a fun read and only around 25 pages. It is available <a href="lockharts_lament.pdf">here (PDF)</a>.</p>]]></content>
    
    
      
      
        
        
    <summary type="html"></summary>
        
      
    
    
    
    
    <category term="models" scheme="http://loreley.one/tags/models/"/>
    
    <category term="math" scheme="http://loreley.one/tags/math/"/>
    
  </entry>
  
  <entry>
    <title>ACDL 2024</title>
    <link href="http://loreley.one/2024-06-acdl/"/>
    <id>http://loreley.one/2024-06-acdl/</id>
    <published>2024-06-14T22:00:00.000Z</published>
    <updated>2025-03-31T21:57:49.710Z</updated>
    
    <content type="html"><![CDATA[<p>The <a href="https://acdl2024.icas.events/">ACDL</a> is a summer school, which, as the name implies, focuses on data science and to a larger extent machine learning. I recently had the pleasure of attending for the first time. This year it was held on the Tuscan coast, and attracted a mostly European audience with many participants from Italy.</p><center><img src="beach.jpg"  width=900  alt="beach"><p><small>The beach at Hotel Riva del Sole, where the event was held</small></p></center><p>The course revolves around the talks, with subjects ranging from clustering and network analysis to large language models. LLM hype seems to be everywhere, and took up roughly half of the lecture time. The talks were mostly technical, and given on a phd student (the majority of the attendees) level. Here follows a list of some of my favorite talks from the event.</p><h4 id="Multimodal-Foundation-Models"><a href="#Multimodal-Foundation-Models" class="headerlink" title="Multimodal Foundation Models"></a>Multimodal Foundation Models</h4><p>by <a href="https://gabrielbm.com/">Gabriel Barth-Maron</a></p><p>This series of lectures was the highlight of the entire course for me, due to its relevance to my work. Gabriel discussed the architecture of multimodal models, as well as techniques for combining and using pretrained backbones in multimodal models. In particular, the <a href="https://arxiv.org/abs/2402.11530">bunny series of models</a> is something I plan to look into more in the future.</p><h4 id="Machine-Learning-for-Modeling-and-Control-of-Complex-Systems"><a href="#Machine-Learning-for-Modeling-and-Control-of-Complex-Systems" class="headerlink" title="Machine Learning for Modeling and Control of Complex Systems"></a>Machine Learning for Modeling and Control of Complex Systems</h4><p>by <a href="https://seas.harvard.edu/person/petros-koumoutsakos">Petros Koumoutsakos</a></p><p>This series was very wide-ranging, but often touched on Koumoutsakos’s work with fluid mechanics. I wasn’t able to follow it in its entirety but still found it very interesting. His work on <a href="https://cse-lab.seas.harvard.edu/research-artificial_intelligence-reinforcement_learning">experience replay</a> is something I will have to come back to.</p><h4 id="Diffusion-Models"><a href="#Diffusion-Models" class="headerlink" title="Diffusion Models"></a>Diffusion Models</h4><p>by <a href="https://chinweihuang.com/">Chin-Wei Huang</a></p><p>I like diffusion models and have played around with them quite a bit. But the math behind them is a little more complex than what I am used to, so I was happy to attend this introductory talk. On a side note <a href="https://www.chenyang.co/diffusion.html">this blog post</a> is still the best introduction to diffusion models that I’m aware of.</p><h4 id="Fusing-Machine-Learning-and-Optimization-for-Engineering"><a href="#Fusing-Machine-Learning-and-Optimization-for-Engineering" class="headerlink" title="Fusing Machine Learning and Optimization for Engineering"></a>Fusing Machine Learning and Optimization for Engineering</h4><p>by <a href="https://sites.gatech.edu/pascal-van-hentenryck/">Pascal van Hentenryck</a></p><p>Optimization is not something I understand very well (yet), but this series of talks was nonetheless great. Pascal spoke about the challenges of optimizing an energy grid, and the unique methods that have been developed to do this.</p><h2 id="Overall"><a href="#Overall" class="headerlink" title="Overall"></a>Overall</h2><p>In my opinion, one of the best parts of attending these events are the people you meet. It’s quite special to meet so many other people who share the same interests as you and are happy to discuss their research (where else can you discuss optimization algorithms on the beach?). I would certainly recommend that you seek out a similar event if you’ve never done so before. <a href="https://acdl2025.icas.events/">Here</a> is the website for next years event. <a href="https://www.summerschoolsineurope.eu/search">This search engine</a> was how I found the ACDL and might also be of use to you.</p>]]></content>
    
    
      
      
        
        
    <summary type="html"></summary>
        
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Double Q-Learning Explained</title>
    <link href="http://loreley.one/2024-03-double_q/"/>
    <id>http://loreley.one/2024-03-double_q/</id>
    <published>2024-03-15T23:00:00.000Z</published>
    <updated>2025-03-31T21:57:49.716Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Q-learning is a popular reinforcement learning algorithm, used for solving Markov Decision Processes (MDP). In some cases, Q-learning doesn’t work well and takes a long time to converge, due to an issue known as the optimizer’s curse or maximization bias. In this post, we’ll take a look at the problem as well as a proposed solution. What follows is a brief recapitulation of MDP’s and Q-learning, followed by a deep dive into Double Q learning, the proposed solution to the problem.</p><h2 id="Recap-of-Q-learning"><a href="#Recap-of-Q-learning" class="headerlink" title="Recap of Q learning"></a>Recap of Q learning</h2><p>A Markov chain consists of states connected through transition probabilities, which determine the likelihood of moving from one state to another. This probability depends only on the current state, not on the sequence of events that preceded it. Some states are accessible only from specific other states, forming a directed network.</p><p>A Markov Decision Process (MDP) extends the concept of a Markov chain by incorporating decisions. It substitutes transition probabilities with actions that represent available choices. Each state in an MDP is linked with a reward, indicating the value of reaching that state. The distinct feature of MDPs is the decision-making aspect, where an agent selects actions to transition between states and accumulate rewards. The goal in an MDP is to find an optimal policy, which is a set of rules defining the best action to take in each state to maximize rewards.</p><p>A trajectory through an MDP is represented using the notation: starting at state <code>S</code>, an action <code>A</code> is chosen from the available options in state <code>S</code>. This leads to a transition to state <code>S'</code> with probability <code>P</code>, and a reward <code>R</code> is received. The tuple <code>(S, A, P, R)</code> describes this process, where <code>P</code> is defined as <code>Pr(S' | S, A)</code>. This sequence repeats at each step until a terminal state is reached, outlining the full trajectory:</p><p><code>S<sub>0</sub>, A<sub>0</sub>, R<sub>1</sub>, S<sub>1</sub>, A<sub>1</sub>, R<sub>2</sub>, S<sub>2</sub>, A<sub>2</sub>, R<sub>3</sub>, ...</code></p><p>The Q(action, value) function under a policy <code>π</code> is formally defined as:</p><p><code>Q<sub>π</sub>(s, a) = E[G | s, a, π]</code></p><p>where <code>E[G | s, a, π]</code> represents the expected total (discounted) reward given that we start in state <code>s</code>, take action <code>a</code>, and then follow policy <code>π</code> for all subsequent decisions. This expectation accounts for the sum of rewards received, starting from <code>s</code> and <code>a</code>, under the guidance of policy <code>π</code>.</p><p>In Q-learning, the objective is to approximate the optimal Q function, which represents the best action values under an optimal policy, regardless of the initial policy used to generate training data. The policy generating our training data decides actions, which might not be optimal. Our aim is to iteratively refine our Q function based on these examples. The algorithm is as follows:</p><center><img src="q_algo.png" alt="q learning algorithm"><p><small>Q-learning algorithm (Sutton and Barto)</small></p></center><p>For a full discussion of Q-learning I recommend the following 2 sources:</p><ul><li><a href="https://huggingface.co/learn/deep-rl-course/unit2/introduction">Hugging Face course on Q-learning</a>. This is a nice quick overview.</li><li>For a full treatment see the RL book by Sutton and Barto, which is available free <a href="http://incompleteideas.net/book/the-book.html">here</a>.</li></ul><h2 id="Dissection-of-the-problem"><a href="#Dissection-of-the-problem" class="headerlink" title="Dissection of the problem"></a>Dissection of the problem</h2><p>A common issue with Q-learning involves how it handles variance in rewards. Consider an MDP where we start in state <code>A</code> with the options to move to <code>B</code> or directly to a terminal state <code>T</code>, neither transition offering any reward. From <code>B</code>, we can transition to several secondary states, <code>C<sub>1</sub>, C<sub>2</sub>, ..., C<sub>n</sub></code>, each associated with a reward from a normal distribution with a negative mean (e.g., -0.1) and a variance (e.g., 1). Transitioning from any <code>C<sub>n</sub></code> to <code>T</code> yields no reward. Ideally, the optimal strategy is to move from <code>A</code> to <code>T</code>, avoiding negative rewards in the <code>C</code> states. However, the stochastic nature of rewards means a visit to any <code>C</code> state might yield a positive reward. The likelihood of receiving a positive reward increases with the number of <code>C</code> states.</p><p>This variance introduces a challenge in Q-learning. The algorithm estimates the Q-value for transitioning from <code>A</code> to <code>B</code> based on the maximum reward obtainable from moving to any <code>C</code> state. Given the rewards are drawn from a distribution, it’s probable to encounter a positive reward in one of the <code>C</code> states during exploration. Consequently, the Q-function may overestimate the value of moving from A to B. Essentially, the “max” operation in the update rule can cause a single overoptimistic estimate to skew the Q-values, leading to incorrect policy decisions.</p><p>A more in-depth explanation can be found in the paper <a href="optimizers_curse.pdf">The Optimizer’s Curse: Skepticism and Postdecision Surprise in Decision Analysis (pdf)</a> by Smith and Winkler.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>A solution to this problem, Double Q-learning, was proposed by <a href="https://papers.nips.cc/paper_files/paper/2010/file/091d584fced301b442654dd8c23b3fc9-Paper.pdf">Hasselt (pdf)</a>. Let’s view our problem through a slightly different lens. The issue arises because we are using the same samples of <code>C</code> twice. Once to estimate the value of taking an action; <code>Q(B, move to C<sub>i</sub>)</code>. Secondly when performing the maximizing operation to determine which <code>C<sub>i</sub></code> is best to move to from state b; <code>max<sub>i</sub> Q(B, C<sub>i</sub>)</code>. If we instead use 2 independent estimates, <code>Q<sub>1</sub></code> and <code>Q<sub>2</sub></code>, we alleviate this problem. <code>Q<sub>1</sub></code> might overestimate the value of moving to a particular state <code>C<sub>i</sub></code>, but it’s very unlikely that <code>Q<sub>2</sub></code> also estimates moving to <code>C<sub>i</sub></code> to be the best action to take from <code>B</code>.</p><p>This sounds confusing, so let’s walk through the original Q-learning update again. After removing the discount (unimportant for our purposes) we are left with:</p><p><code>Q(s, a) = Q(s, a) + α * (reward + max a Q(s’,a) - Q(s,a))</code></p><p>Conceptually we are doing the following:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># the old/current estimate of taking action a in state s</span><br><span class="line">old = q(s,a)</span><br><span class="line"></span><br><span class="line"># new estimate is the reward, plus our best estimate for future rewards starting from the next state</span><br><span class="line">new = r +  max a q(s’, a) </span><br><span class="line"></span><br><span class="line"># the discrepancy between the 2 estimates</span><br><span class="line">error = new - old</span><br><span class="line"></span><br><span class="line"># update our estimate:</span><br><span class="line">q(s,a) = old + learning_rate * error</span><br></pre></td></tr></table></figure><p>What’s important to realize is we are making use of the same Q function to get our estimates twice. Once for <code>Q(s’,a)</code> to get the value of the new state action pair, and again when performing <code>max a</code> on <code>Q(s’,a)</code> to decide what value of <code>a</code> to use. </p><p>The double Q-learning solution to our problem says we should use two independent estimates of the state-action values. Our update is now as follows:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># the old/current estimate of taking action a in state s</span><br><span class="line">old = q1(s,a)</span><br><span class="line"></span><br><span class="line"># use q1 to estimate the best action to take in the next state</span><br><span class="line">best_action_in_state_s’ = argmax a q1(s’, a)</span><br><span class="line"></span><br><span class="line"># use q2 to determine what the value of the action is</span><br><span class="line">value of s’ = q2(s’, best_action_in_state_s’)</span><br><span class="line"></span><br><span class="line"># new estimate is the reward, plus our best estimate for future rewards starting from the next state</span><br><span class="line">new = r + value of s’</span><br><span class="line"></span><br><span class="line">error = new - old</span><br><span class="line"></span><br><span class="line">updated q1(s,a) = old + learning_rate * error</span><br></pre></td></tr></table></figure><p>The full double Q-learning algorithm is as follows:</p><center><img src="double_algo.png" alt="double q algorithm"><p><small>Double Q-learning (Sutton and Barto)</small></p></center><p>Since <code>Q1</code> is updated on different samples than <code>Q2</code>, they are not subject to the maximization bias. The algorithm does require more memory to store two Q functions. The computational cost stays the same.</p><h2 id="Code-Walkthrough"><a href="#Code-Walkthrough" class="headerlink" title="Code Walkthrough"></a>Code Walkthrough</h2><p>The first time I went through this, it was a bit of a head-scratcher, so let’s walk through the code in python to make it more concrete. We will be using the exact same example MDP as above. We will run both Q-learning and Double Q-learning and compare their results. The full code is available <a href="https://gist.github.com/BasedLukas/bda5cfed389e42108fc9f6a8daeb7cd7">here</a>.</p><h5 id="Create-a-Markov-process-Note-that-the-values-of-states-C-are-drawn-from-N-0-1-1"><a href="#Create-a-Markov-process-Note-that-the-values-of-states-C-are-drawn-from-N-0-1-1" class="headerlink" title="Create a Markov process. Note that the values of states C are drawn from N(-0.1, 1)."></a>Create a Markov process. Note that the values of states <code>C</code> are drawn from <code>N(-0.1, 1)</code>.</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_reward</span>(<span class="params">state: <span class="built_in">str</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">   <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   Returns the reward for transitioning into a given state.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   Args:</span></span><br><span class="line"><span class="string">   - state: The state transitioned into.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   Returns:</span></span><br><span class="line"><span class="string">   - A float representing the reward for that transition.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   Raises:</span></span><br><span class="line"><span class="string">   - ValueError: If an invalid state is provided.</span></span><br><span class="line"><span class="string">   &quot;&quot;&quot;</span></span><br><span class="line">   <span class="keyword">if</span> state == <span class="string">&quot;a&quot;</span>:</span><br><span class="line">       <span class="keyword">raise</span> ValueError(<span class="string">&quot;a should not be passed as a param as it&#x27;s the starting state&quot;</span>)</span><br><span class="line">   <span class="keyword">if</span> state == <span class="string">&#x27;b&#x27;</span> <span class="keyword">or</span> state == <span class="string">&#x27;terminal&#x27;</span>:</span><br><span class="line">       <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">   <span class="keyword">if</span> <span class="string">&#x27;c&#x27;</span> <span class="keyword">in</span> state:</span><br><span class="line">       <span class="keyword">return</span> np.random.normal(-<span class="number">0.1</span>, <span class="number">1</span>)</span><br><span class="line">   <span class="keyword">raise</span> ValueError(<span class="string">f&quot;state: <span class="subst">&#123;state&#125;</span> not recognized&quot;</span>)</span><br><span class="line"></span><br><span class="line">transitions = &#123;</span><br><span class="line">    <span class="string">&quot;a&quot;</span>: [<span class="string">&quot;terminal&quot;</span>, <span class="string">&quot;b&quot;</span>],</span><br><span class="line">    <span class="string">&quot;b&quot;</span>: [<span class="string">&quot;c&quot;</span>+<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(number_of_c_states)]</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(number_of_c_states):</span><br><span class="line">    transitions[<span class="string">f&quot;c<span class="subst">&#123;i&#125;</span>&quot;</span>] = [<span class="string">&quot;terminal&quot;</span>]</span><br></pre></td></tr></table></figure><h5 id="Our-Q-functions-are-simply-dictionaries"><a href="#Our-Q-functions-are-simply-dictionaries" class="headerlink" title="Our Q functions are simply dictionaries."></a>Our <code>Q</code> functions are simply dictionaries.</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">q:  Dict[Tuple[str, int], float] = &#123;&#125;</span><br><span class="line">q1: Dict[Tuple[str, int], float] = &#123;&#125;</span><br><span class="line">q2: Dict[Tuple[str, int], float] = &#123;&#125;</span><br></pre></td></tr></table></figure><h5 id="Now-define-a-function-to-do-the-Q-learning-update-max-a-uses-the-provided-q-to-find-the-best-next-value"><a href="#Now-define-a-function-to-do-the-Q-learning-update-max-a-uses-the-provided-q-to-find-the-best-next-value" class="headerlink" title="Now define a function to do the Q-learning update. max_a uses the provided q to find the best next value."></a>Now define a function to do the Q-learning update. <code>max_a</code> uses the provided <code>q</code> to find the best next value.</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">q_update</span>(<span class="params"></span></span><br><span class="line"><span class="params">       state: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">       action: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">       new_state: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">       reward: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">       alpha: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">       q: <span class="type">Dict</span></span></span><br><span class="line"><span class="params">   </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">   <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   In-place update of Q-values for Q-learning.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   Args:</span></span><br><span class="line"><span class="string">       state: The current state.</span></span><br><span class="line"><span class="string">       action: The action taken in the current state.</span></span><br><span class="line"><span class="string">       new_state: The state reached after taking the action.</span></span><br><span class="line"><span class="string">       reward: The reward received after taking the action.</span></span><br><span class="line"><span class="string">       alpha: The learning rate.</span></span><br><span class="line"><span class="string">       q: The Q-values dictionary.</span></span><br><span class="line"><span class="string">   &quot;&quot;&quot;</span></span><br><span class="line">   current_q = q.get((state, action), <span class="number">0</span>)  <span class="comment"># Current Q-value estimation</span></span><br><span class="line">   max_next = max_a(new_state, q)  <span class="comment"># Maximum Q-value for the next state</span></span><br><span class="line">   target = reward + gamma * max_next  <span class="comment"># TD Target</span></span><br><span class="line">   td_error = target - current_q  <span class="comment"># TD Error</span></span><br><span class="line">   update = alpha * td_error  <span class="comment"># TD Update</span></span><br><span class="line">   q[(state, action)] = current_q + update</span><br></pre></td></tr></table></figure><h5 id="The-Double-Q-learning-update-argmax-a-finds-the-best-next-action-using-the-provided-Q-function"><a href="#The-Double-Q-learning-update-argmax-a-finds-the-best-next-action-using-the-provided-Q-function" class="headerlink" title="The Double Q-learning update. argmax_a finds the best next action, using the provided Q function."></a>The Double Q-learning update. <code>argmax_a</code> finds the best next action, using the provided Q function.</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">double_q_update</span>(<span class="params"></span></span><br><span class="line"><span class="params">       state: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">       action: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">       new_state: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">       reward: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">       alpha: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">       q1: <span class="type">Dict</span>,</span></span><br><span class="line"><span class="params">       q2: <span class="type">Dict</span></span></span><br><span class="line"><span class="params">   </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">   <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   In-place update of Q-values for Double Q-learning.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   Args:</span></span><br><span class="line"><span class="string">       state: The current state.</span></span><br><span class="line"><span class="string">       action: The action taken in the current state.</span></span><br><span class="line"><span class="string">       new_state: The state reached after taking the action.</span></span><br><span class="line"><span class="string">       reward: The reward received after taking the action.</span></span><br><span class="line"><span class="string">       alpha: The learning rate.</span></span><br><span class="line"><span class="string">       q1: The first Q-values dictionary.</span></span><br><span class="line"><span class="string">       q2: The second Q-values dictionary.</span></span><br><span class="line"><span class="string">   &quot;&quot;&quot;</span></span><br><span class="line">   qs = [q1, q2]  <span class="comment"># List of Q dictionaries</span></span><br><span class="line">   random.shuffle(qs)  <span class="comment"># Randomly shuffle to choose one for updating</span></span><br><span class="line">   qa, qb = qs  <span class="comment"># qa is the Q to update, qb</span></span><br><span class="line"></span><br><span class="line"> <span class="keyword">is</span> used <span class="keyword">for</span> target calculation</span><br><span class="line"></span><br><span class="line">   current_q = qa.get((state, action), <span class="number">0</span>)  <span class="comment"># Current Q-value estimation</span></span><br><span class="line">   best_action = argmax_a(new_state, qa)  <span class="comment"># Best action based on qa</span></span><br><span class="line">   target = reward + gamma * qb.get((new_state, best_action), <span class="number">0</span>)  <span class="comment"># TD Target using qb</span></span><br><span class="line">   error = target - current_q  <span class="comment"># TD Error</span></span><br><span class="line">   update = alpha * error  <span class="comment"># TD Update</span></span><br><span class="line">   qa[(state, action)] = current_q + update</span><br></pre></td></tr></table></figure><h5 id="At-this-point-we-simulate-both"><a href="#At-this-point-we-simulate-both" class="headerlink" title="At this point, we simulate both."></a>At this point, we simulate both.</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">simulate</span>(<span class="params"></span></span><br><span class="line"><span class="params">       epoch: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">       q: <span class="type">Dict</span>,</span></span><br><span class="line"><span class="params">       q2: <span class="type">Optional</span>[<span class="type">Dict</span>] = <span class="literal">None</span></span></span><br><span class="line"><span class="params">   </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">   <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   Simulate an epoch of the agent&#x27;s interaction with the environment, updating Q-values based on observed transitions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   Args:</span></span><br><span class="line"><span class="string">       epoch: The current epoch of the simulation.</span></span><br><span class="line"><span class="string">       q: The Q-values dictionary for Q-learning or the primary Q-values dictionary for Double Q-learning.</span></span><br><span class="line"><span class="string">       q2: The secondary Q-values dictionary for Double Q-learning, if applicable.</span></span><br><span class="line"><span class="string">   &quot;&quot;&quot;</span></span><br><span class="line">   double = q2 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">   state = <span class="string">&#x27;a&#x27;</span></span><br><span class="line">   <span class="keyword">while</span> state != <span class="string">&#x27;terminal&#x27;</span>:</span><br><span class="line">       <span class="keyword">if</span> double:</span><br><span class="line">           action = policy(state, epoch, q, q2)</span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">           action = policy(state, epoch, q)</span><br><span class="line">       new_state = transitions[state][action]</span><br><span class="line">       reward = get_reward(new_state)</span><br><span class="line">      </span><br><span class="line">       <span class="keyword">if</span> double:</span><br><span class="line">           double_q_update(</span><br><span class="line">               state=state,</span><br><span class="line">               action=action,</span><br><span class="line">               new_state=new_state,</span><br><span class="line">               reward=reward,</span><br><span class="line">               alpha=lr,</span><br><span class="line">               q1=q,</span><br><span class="line">               q2=q2</span><br><span class="line">               )</span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">           q_update(state, action, new_state, reward, lr, q)</span><br><span class="line"></span><br><span class="line">       state = new_state</span><br></pre></td></tr></table></figure><p>Now we can plot the results. They will differ every time, but mostly look something like this.</p><center><img src="double_q.png" alt="my results"><p><small>My results</small></p></center><p>We can clearly see how Q-learning has trouble converging on the correct result. I was so excited when I got this result, because it mirrors very closely with that of Sutton and Barto!</p><center><img src="sutton.png" alt="Suttons results"><p><small>Sutton's results (Sutton and Barto)</small></p></center><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>I went into this deep dive because I had trouble understanding this myself. I’m still not entirely sure I understand it, but writing out the code certainly helps. Sutton and Barto’s <a href="http://incompleteideas.net/book/the-book.html">book</a> on RL really is a must. Other useful resources are these series on YouTube:</p><ul><li><a href="https://www.youtube.com/playlist?list=PLwRJQ4m4UJjNymuBM9RdmB3Z9N5-0IlY0">Foundations of deep RL</a></li><li><a href="https://www.youtube.com/playlist?list=PLqYmG7hTraZBKeNJ-JE_eyJHZ7XgBoAyb">DeepMind x UCL | Reinforcement Learning Course</a></li></ul><p>And of course, Andrej Karpathy’s <a href="http://karpathy.github.io/2016/05/31/rl/">blog post</a>.</p>]]></content>
    
    
      
      
        
        
    <summary type="html"></summary>
        
      
    
    
    
    
    <category term="python" scheme="http://loreley.one/tags/python/"/>
    
    <category term="models" scheme="http://loreley.one/tags/models/"/>
    
    <category term="probability" scheme="http://loreley.one/tags/probability/"/>
    
    <category term="reinforcement learning" scheme="http://loreley.one/tags/reinforcement-learning/"/>
    
  </entry>
  
  <entry>
    <title>Will Gzip Replace Neural Networks for Text Classification?</title>
    <link href="http://loreley.one/2023-07-gzip/"/>
    <id>http://loreley.one/2023-07-gzip/</id>
    <published>2023-07-18T22:00:00.000Z</published>
    <updated>2025-03-31T21:57:49.721Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Large language models are currently all the rage when it comes to text classification. However, a recent <a href="https://aclanthology.org/2023.findings-acl.426/">research paper</a> offers an interesting non-parametric alternative. The proposed method is elegant in its simplicity: it combines a text compressor, gzip, with a k-nearest-neighbour classifier. This approach requires no training parameters, making it a lightweight and universally adaptable solution.</p><p>The cornerstone of this method lies in two key ideas: first, compressors are good at capturing regularities in data, and second, data points from the same category share more regularity than those from different categories. </p><p>In this article, we explore this approach to text classification, discussing its rationale, how it works, and its practical implementation in Python.</p><h2 id="The-Mechanics-of-Compression-and-Classification"><a href="#The-Mechanics-of-Compression-and-Classification" class="headerlink" title="The Mechanics of Compression and Classification"></a>The Mechanics of Compression and Classification</h2><p>The technique proposed in the paper uses combination of a text compressor and a k-nearest-neighbor classifier. But what makes this a viable method for text classification?</p><p>At the heart of this approach is the idea that data compressors, like gzip, are skilled at capturing patterns, or regularities, in data. As an example, consider the following string ‘aaaaaabbb’ which can be compressed as ‘6<em>a 3</em>b’. Similarly, a data compressor finds patterns and regularities in the data and uses them to compress it, which is exactly what gzip does with text data.</p><p>The second key idea is that data points from the same category have more in common, they share more regularity than data points from different categories. For example, English text contains more instances of ‘-ing’ or similar arrangements of letters than does French. This forms the basis for classifying texts using the compressed length, or how much the data can be compressed.</p><h4 id="LZ77-Patterns-and-References"><a href="#LZ77-Patterns-and-References" class="headerlink" title="LZ77: Patterns and References"></a>LZ77: Patterns and References</h4><p>At the core of the gzip algorithm are two primary compression techniques: LZ77 and Huffman encoding. Let’s begin our exploration with the former - the LZ77 algorithm.</p><p>LZ77 operates on a straightforward principle: it replaces repeating data with references to its prior occurrence. Imagine the phrase “apple apple”. LZ77 would replace the second “apple” with a reference to its first appearance, considerably reducing the data footprint.</p><p>The algorithm analyzes a ‘window’ of characters, retrospectively scanning for matches. When a match is found, it is replaced by a reference pointing to the initial occurrence of that string. This simple replacement procedure effectively compacts data, especially in instances of high repetition.</p><p>Consider a text filled with recurring phrases or words - LZ77 transforms this repetitiveness into a compression advantage. The same piece of data doesn’t need to be stored twice; a reference to its first occurrence will suffice. Thus, texts exhibiting more patterns are subject to more effective compression than random text. </p><p>Here is a simple example:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Never gonna give you up</span><br><span class="line">Never gonna let you down</span><br><span class="line">Never gonna run around and desert you</span><br><span class="line">Never gonna make you cry</span><br><span class="line">Never gonna say goodbye</span><br><span class="line">Never gonna tell a lie and hurt you</span><br><span class="line">We&#x27;ve known each other for so long</span><br><span class="line">Your heart&#x27;s been aching, but you&#x27;re too shy to say it (say it)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Post LZ77 compression, the lyrics transform into:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Never gonna(6, 2)i(12, 2) you up(24, 13)let(23, 5)down(49, 13)run ar(49, 2)nd(7, 2)n(4, 2)des(27, 2)t(43, 4)</span><br><span class="line">(38, 12)make(21, 4) cry(25, 13)say(35, 3)odbye(49, 13)tell (31, 2)lie(6, 2)nd hurt you</span><br><span class="line">We&#x27;(37, 2) known each other fo(4, 2)so(47, 2)ong</span><br><span class="line">Y(39, 2)r(49, 2)ea(50, 2)&#x27;s bee(41, 2)a(40, 2)i(25, 2),(13, 2)ut y(30, 2)&#x27;re to(46, 2)shy(8, 3) sa(7, 2)i(25, 2)((8, 6))</span><br></pre></td></tr></table></figure><p>Here, each backreference is denoted as <code>(number of places to go backwards, number of characters to replace)</code>. As the compression progresses, more words are replaced by these backreferences, significantly reducing the data footprint.</p><p>However, this process isn’t without its challenges. One potential issue is distinguishing between actual text (literals) and backreferences. Currently, each backreference is enclosed in braces, which becomes problematic when the original text also contains braces. This could be addressed by escaping them, but it introduces redundancy. Huffman encoding, the other key technique utilized by gzip, helps overcome this issue and further compresses the text, which we will explore in the following section.</p><h4 id="Huffman-Encoding-Shorter-Codes-for-Frequent-Characters"><a href="#Huffman-Encoding-Shorter-Codes-for-Frequent-Characters" class="headerlink" title="Huffman Encoding: Shorter Codes for Frequent Characters"></a>Huffman Encoding: Shorter Codes for Frequent Characters</h4><p>After the compression achieved by LZ77, gzip employs Huffman encoding to maximize the compression. Huffman encoding uses variable-length codes to represent each character in the text, where the code’s length is inversely related to the frequency of the character’s occurrence. This method allows us to save additional space by giving shorter codes to characters that appear more frequently.</p><p>Let’s demonstrate this process with an example, using the text <code>AAABBCDDDDEEEEE</code>. Our first task is to tally the frequency of each character. The order is irrelevant at this stage:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A:3</span><br><span class="line">B:2</span><br><span class="line">C:1</span><br><span class="line">D:4</span><br><span class="line">E:5</span><br></pre></td></tr></table></figure><p>Next, we group the two least frequent characters (C and B) into a tree and keep it aside for future use:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  BC:3</span><br><span class="line">  /  \</span><br><span class="line">B:2  C:1</span><br></pre></td></tr></table></figure><p>We then add the total frequency of B and C, and reintroduce the newly created tree into our frequency table:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A:3</span><br><span class="line">D:4</span><br><span class="line">E:5</span><br><span class="line">BC:3</span><br></pre></td></tr></table></figure><p>We repeat this process, this time selecting the two lowest frequencies (A and BC):</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ABC:6</span><br><span class="line">  /  \</span><br><span class="line">A:3  BC:3</span><br><span class="line">       /  \</span><br><span class="line">     B:2  C:1</span><br></pre></td></tr></table></figure><p>The frequency table updates to:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">D:4</span><br><span class="line">E:5</span><br><span class="line">ABC:6</span><br></pre></td></tr></table></figure><p>Next, we select D and E to form:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  DE: 9</span><br><span class="line">  /  \</span><br><span class="line">D:4  E:5</span><br></pre></td></tr></table></figure><p>This leads to an updated frequency table:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ABC:6</span><br><span class="line">DE:9</span><br></pre></td></tr></table></figure><p>With just two elements left, we can construct our final tree using all the mini trees generated so far:</p><center><img src="huffman.jpeg" alt="huffman tree"><p><small>The completed Huffman Tree</small></p></center><p>Finally, we assign unique codes for each letter: 0 for left and 1 for right. For instance, the code for D is 10. To reach D from the root, we move first to the right, then to the left. This system is efficient since we don’t need to denote when one code ends and the next begins — we simply stop whenever we reach a leaf. As a result, the most frequently appearing characters have the shortest codes:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A = 00</span><br><span class="line">E = 11</span><br><span class="line">D = 10</span><br><span class="line">B = 010</span><br><span class="line">C = 011</span><br></pre></td></tr></table></figure><p>With this method, we can compress text quite effectively. Recall our earlier problem of distinguishing between backreferences and literals. Given the frequent recurrence of backreferences in the text, they would receive their own short, unique codes, thereby enhancing the compression efficiency. It’s important to note that while we’ve simplified the process here, the complete gzip algorithm is more complex.</p><h3 id="Classification-Through-Compression"><a href="#Classification-Through-Compression" class="headerlink" title="Classification Through Compression"></a>Classification Through Compression</h3><p>Now that we understand how compression works, we can go back to text classification. Consider three examples, <code>x1</code>, <code>x2</code>, and <code>x3</code>. <code>x1</code> and <code>x2</code> belong to the same category, while <code>x3</code> falls into a different category. Let’s define <code>C(·)</code> as the compressed length of an object. The assumption we make is that <code>C(x1x2) - C(x1) &lt; C(x1x3) - C(x1)</code>. Here, <code>C(x1x2)</code> represents the compressed length of the concatenated <code>x1</code> and <code>x2</code>. Essentially, <code>C(x1x2) - C(x1)</code> is the additional byte count required to encode <code>x2</code> given the prior information of <code>x1</code>.</p><p>This idea forms the basis of a distance metric inspired by the Kolmogorov complexity — a theoretical measure defined as the length of the shortest binary program that can generate a string <code>x</code>. Due to the inherent uncomputability of the Kolmogorov complexity, a normalized, and computable alternative, the Normalized Compression Distance (NCD), is used instead. NCD uses the compressed length <code>C(x)</code> as an approximation for the Kolmogorov complexity <code>K(x)</code>. Formally:</p><p><code>NCD(x, y) = [C(xy) - min&#123;C(x), C(y)&#125;] / max&#123;C(x), C(y)&#125;</code></p><p>The use of compressed length rests on the assumption that the length of <code>x</code> when maximally compressed by a compressor is approximately equal to <code>K(x)</code>. For our purposes, gzip is used as the compressor. Consequently, <code>C(x)</code> denotes the length of <code>x</code> after gzip compression, while <code>C(xy)</code> represents the compressed length of <code>x</code> and <code>y</code> concatenated. With the distance matrix provided by NCD, we can apply k-nearest-neighbors for classification.</p><p>Let’s delve into how this is implemented in practice using Python. We can start with two text strings representing different categories, GroupA and GroupB, and a third string, StringUnknown, which we wish to classify. We compress each of these strings using gzip and calculate their respective lengths. Then, we concatenate StringUnknown with each group, compress the result and calculate their lengths.</p><p>Next, we compute the NCD for the unknown string and each group by subtracting the smallest compressed length of the group or the unknown string from the compressed length of the concatenated string, then dividing by the maximum compressed length of the group or the unknown string. This gives us a normalized measure of the “distance” of the unknown string from each group.</p><p>The group with the smallest NCD to the unknown string is considered the most likely group that the unknown string belongs to. In essence, the smaller the NCD, the greater the similarity between the unknown string and the group.</p><script src="https://gist.github.com/BasedLukas/42022b382660a27a7044770893572b18.js"></script><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CompA:  110</span><br><span class="line">CompB:  102</span><br><span class="line">CompA_Unknown:  153</span><br><span class="line">CompB_Unknown:  163</span><br><span class="line">A_Diff:  43</span><br><span class="line">B_Diff:  61</span><br><span class="line"></span><br><span class="line">NCD_A:  0.42727272727272725</span><br><span class="line">NCD_B:  0.5754716981132075</span><br><span class="line">StringUnknown is in GroupA</span><br></pre></td></tr></table></figure><p>This approach, using the NCD offers is just one method for computing the distance. However, other distance metrics can be employed. </p><p>The following method estimates the cross entropy between the probability distribution built on class <code>c</code> and the document <code>d</code>: <code>Hc(d)</code>. The process involves the following steps:</p><ol><li>For each class <code>c</code>, concatenate all samples <code>dc</code> in the training set belonging to <code>c</code>.</li><li>Compress <code>dc</code> as one long document to get the compressed length <code>C(dc)</code>.</li><li>Concatenate the given test sample <code>du</code> with <code>dc</code> and compress to get <code>C(dcdu)</code>.</li><li>The predicted class is <code>arg min C(dcdu) - C(dc)</code>.</li></ol><p>In essence, this technique uses <code>C(dcdu) - C(dc)</code> as the distance metric, which is computationally more efficient than pairwise distance matrix computation on small datasets. However, it has some drawbacks. Most compressors, including gzip (as mentioned above), have a limited “window” they can use to search back through the repeated string or keep a record of. As a result, even with numerous training samples, the compressor may not fully exploit them. Additionally, compressing <code>dcdu</code> can be slow for large <code>dc</code>, a problem not solved by parallelization. These limitations prevent this method from being applicable to extremely large datasets. As such, the NCD-based approach presented above, which avoids these limitations, becomes particularly appealing for text classification tasks on large datasets.</p><h2 id="Downsides-and-Drawbacks"><a href="#Downsides-and-Drawbacks" class="headerlink" title="Downsides and Drawbacks"></a>Downsides and Drawbacks</h2><p>Despite the ingenuity of applying compression algorithms for text classification, the approach is not without its limitations. The size of the lookback window of the LZ77 algorithm, for instance, presents a potential drawback. This algorithm searches the prior text to find matches, but its effectiveness can diminish when dealing with very long text.</p><p>In addition, the method does not grasp the subtleties of language, such as synonyms or context-specific meanings. The absence of this linguistic sophistication may hinder its performance on tasks requiring a deeper understanding of language nuances. Furthermore, the computational intensity of this approach can escalate rapidly when dealing with larger datasets, given the O(n^2) complexity of K-Nearest Neighbors (KNN). </p><p>Lastly, some controversy surrounds the code and results of the original paper that introduced this method. Some of the datasets used seem to have issues, though not due to the authors’ mistakes. Additionally, there has been some debate regarding how the results have been scored. For a detailed look at these issues, you can check out <a href="https://kenschutte.com/gzip-knn-paper/">this blog post</a> and follow the discussion on <a href="https://github.com/bazingagin/npc_gzip/issues/3">GitHub</a>.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>This is a really interesting approach, and while it may not be perfect, it provides much food for thought.</p><p>To get hands-on with the concepts discussed in this blog, you can check out <a href="https://github.com/BasedLukas/zip_classification">this repository that I made</a>. It provides a simple implementation of LZ77 and Huffman encoding, allowing you to experiment with these algorithms and see how they work in practice.</p><p>For a more in-depth understanding of gzip, consider reading <a href="https://www.infinitepartitions.com/art001.html">this blog post</a>. <a href="https://www.zlib.net/feldspar.html">This article</a> offers an excellent explanation of the LZ77 algorithm. Of course, you should read the original paper, available <a href="https://aclanthology.org/2023.findings-acl.426/">here</a>, which is very well written and understandable.</p>]]></content>
    
    
      
      
        
        
    <summary type="html"></summary>
        
      
    
    
    
    
    <category term="python" scheme="http://loreley.one/tags/python/"/>
    
    <category term="NLP" scheme="http://loreley.one/tags/NLP/"/>
    
    <category term="models" scheme="http://loreley.one/tags/models/"/>
    
  </entry>
  
  <entry>
    <title>Designing a Simple 8 Bit CPU Emulator in Python</title>
    <link href="http://loreley.one/2023-07-cpu/"/>
    <id>http://loreley.one/2023-07-cpu/</id>
    <published>2023-07-03T22:00:00.000Z</published>
    <updated>2025-03-31T21:57:49.710Z</updated>
    
    <content type="html"><![CDATA[<p><em>(2024-12-07) Note: See <a href="https://loreley.one/2024-12-wasm/">this blogpost</a> of mine to interact with the CPU and solve the maze.</em></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>A while back, I came across an interesting game on Steam called <a href="https://turingcomplete.game/">Turing Complete</a>. The objective of the game is to design a Turing complete CPU from scratch, and it guides players through each step of the process. Starting with the basics of logic gates, the building blocks of a CPU, players tackle progressively more complex challenges until they reach the point of designing their own CPU capable of performing simple tasks. I found the game captivating and spent an unhealthy amount of time in it.</p><center><img src="turing_complete.jpg" alt="turing_complete"><p><small>Turing Complete gameplay</small></p></center><p>After completing the game, I decided it would be fun to create a Python emulator for a similar CPU. While it’s relatively easy to make a basic emulator in Python due to its high-level nature, I chose a different approach. I wanted to build the CPU entirely from scratch, deriving the logic from the fundamental functionality of logic gates. This means that the CPU’s performance is determined solely by simple true&#x2F;false comparisons, without relying on if statements or other control flows. It does make the code a bit harder to read at times, but by merely changing the function of a single logic gate, you can witness how the entire CPU’s behavior is affected (spoiler alert: it stops working).</p><h2 id="Logic-Gates"><a href="#Logic-Gates" class="headerlink" title="Logic Gates"></a>Logic Gates</h2><p>The design starts with the logic gates. Here is an excerpt of the code</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">and_</span>(<span class="params">*args:<span class="built_in">bool</span></span>)-&gt;<span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">all</span>(args))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">or_</span>(<span class="params">*args:<span class="built_in">bool</span></span>)-&gt;<span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(<span class="built_in">any</span>(args))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">not_</span>(<span class="params">*args:<span class="built_in">bool</span></span>)-&gt;<span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(<span class="keyword">not</span> <span class="built_in">all</span>(args))</span><br></pre></td></tr></table></figure><p>The logic gates perform simple comparisons and return true or false values. For example the AND gate returns true only if both of its inputs are true. The OR gate returns true if either (or both) of its inputs are true.</p><center><img src="logic_gates.jpg" alt="logic gates"><p><small>logic gate symbols</small></p></center><h2 id="Basic-Components"><a href="#Basic-Components" class="headerlink" title="Basic Components"></a>Basic Components</h2><p>Once we have our logic gates, we can utilize them to create essential components. Let’s focus on the full adder as an example. The purpose of a full adder is to take two binary inputs and perform addition on them. For instance, when adding 0 + 0, the output is 0. When adding 1 + 0, the output is 1.</p><p>However, adding 1 + 1 poses a challenge. In binary, we lack a way to represent the number 2 directly. To address this, we introduce a carry bit, similar to carrying over a digit when adding two decimal numbers that exceed 9. Additionally, we have a carry input to account for any carry bits from previous additions. </p><center><img src="full_adder.png" alt="full adder"><p><small>full adder design</small></p></center><p>A truth table is a structured table that presents the outputs corresponding to all possible input combinations. It allows us to systematically analyze the behavior of a component or system under consideration. In the case of a full adder, the truth table would display the sum output and carry output for each potential combination of binary inputs and carry input. By checking the truth table, we can see how the full adder operates under different input scenarios.</p><center><img src="full_adder_truth.png" alt="full adder truth table"><p><small>full adder truth table</small></p></center><p>The above design can now be implemented in code, using the logic gates we have created previously. In this case I first made a half adder (which doesn’t have a carry in) and used two of them to construct a full adder. Notice how all the logic is dependent on the operation of the logic gates.</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">half_adder</span>(<span class="params">input1:<span class="built_in">bool</span>, input2:<span class="built_in">bool</span></span>):</span><br><span class="line">    <span class="keyword">return</span> sn(</span><br><span class="line">        <span class="built_in">sum</span>=xor(input1, input2),</span><br><span class="line">        carry=and_(input1, input2)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">full_adder</span>(<span class="params">input1:<span class="built_in">bool</span>, input2:<span class="built_in">bool</span>, carry_in:<span class="built_in">bool</span></span>):</span><br><span class="line">    half_adder1 = half_adder(input1, input2)</span><br><span class="line">    half_adder2 = half_adder(half_adder1.<span class="built_in">sum</span>, carry_in)</span><br><span class="line">    out = sn(</span><br><span class="line">        <span class="built_in">sum</span>=half_adder2.<span class="built_in">sum</span>,</span><br><span class="line">        carry=or_(half_adder1.carry, half_adder2.carry)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>After creating a number of basic components such as these, we create more complex components such as an ALU (Arithmetic Logic Unit). The task of the ALU is to perform simple mathematical operations, such as adding 2 numbers together. In this case the ALU can only perform 4 simple operations; Addition, Subtraction, and two logical operations AND and OR. I took inspiration from this 32 bit ALU design, although mine only has 8 bits.</p><center><img src="ALU.png" alt="alu"><p><small>32 bit ALU design</small></p></center><h1 id="The-Full-CPU"><a href="#The-Full-CPU" class="headerlink" title="The Full CPU"></a>The Full CPU</h1><p>The design of the CPU includes six registers, an input, and an output, along with an ALU. Additionally, there is a unit that can carry out comparisons between a value and zero. The CPU operates by executing one of four distinct types of operations:</p><ul><li><p>Immediate: This operation is for moving a given value into register 0. </p></li><li><p>Arithmetic: The operands for any arithmetic operation are always register 1 and register 2, and the resultant output is stored in register 3.</p></li><li><p>Copy: This operation is used for duplicating values from one register to another or to the output. For example, ‘copy 0 6’ copies from register 0 to the output, and ‘copy 5 3’ copies from register 5 to register 3.</p></li><li><p>Evaluation: This operation evaluates the value in register 3 against zero. If the condition is true, it sets the program counter to the value in register 0.</p></li></ul><center><img src="full_cpu.jpeg" alt="full cpu"><p><small>CPU design</small></p></center><p>Using just these operations we have already created a turing complete CPU! However writing code for it would be challenging as we would have to write everything in binary. To solve this I made a simple assembler that converts assembly code to binary. It also adds a number of useful features such as labels. Labels allow you to mark a point in your program to jump to, making it much easier to create loops in your code. Let’s take a look at a simple program. </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># create a marker at the beginning of the program where we can jump to</span><br><span class="line">label start </span><br><span class="line"></span><br><span class="line"># read from input (reg6) into reg1</span><br><span class="line">copy 6 1</span><br><span class="line"></span><br><span class="line"># add reg 1 and 2, store the result in reg3</span><br><span class="line">add</span><br><span class="line"></span><br><span class="line">#copy result from reg3 into reg2</span><br><span class="line">copy 3 2</span><br><span class="line"></span><br><span class="line"># loop back to start if the value is not negative</span><br><span class="line">start</span><br><span class="line">eval &gt;=</span><br><span class="line"></span><br><span class="line"># Once the value overflows and becomes negative send the result to the output</span><br><span class="line">copy 3 6</span><br></pre></td></tr></table></figure><p>In the simple program above, the value 1 is continuously being fed into the CPU. At each iteration we add it to the value stored in register 2, so that we increment the value by 1. Eventually the value grows large enough that it overflows and becomes negative. This is because in binary the most significant bit (MSB) is used to represent negative numbers. Once this happens the program stops running.</p><h1 id="Solve-the-Maze"><a href="#Solve-the-Maze" class="headerlink" title="Solve the Maze"></a>Solve the Maze</h1><p>Now that we have a working CPU, we need something to do with it. So I designed a simple maze that a robot needs to navigate through. The robot can only see one square ahead, and is controlled by the CPU. In order to solve the maze, I implemented a simple algorithm - following the wall. Using this technique the robot is able to find its way through the maze.</p><center><img src="maze.gif" alt="maze"><p><small>Robot solving maze</small></p></center><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># robot recognizes these commands:</span><br><span class="line"># 1 = turn left </span><br><span class="line"># 2 = turn right </span><br><span class="line"># 3 = step forward</span><br><span class="line"># To execute a command send the corresponding value to the output (reg 6)</span><br><span class="line"># robot inputs (reg 6) to CPU:</span><br><span class="line"># 1 = wall</span><br><span class="line"># 0 = clear</span><br><span class="line"></span><br><span class="line">start</span><br><span class="line">eval always</span><br><span class="line"></span><br><span class="line">### routines ###</span><br><span class="line"></span><br><span class="line">label uturn</span><br><span class="line">2</span><br><span class="line">copy 0 6</span><br><span class="line">copy 0 6</span><br><span class="line">start</span><br><span class="line">eval always</span><br><span class="line"></span><br><span class="line">label right </span><br><span class="line">2</span><br><span class="line">copy 0 6</span><br><span class="line">start</span><br><span class="line">eval always</span><br><span class="line"></span><br><span class="line">label left</span><br><span class="line">1</span><br><span class="line">copy 0 6</span><br><span class="line">start</span><br><span class="line">eval always</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### start main loop ###</span><br><span class="line"></span><br><span class="line"># take a step forwards</span><br><span class="line">label start</span><br><span class="line">3</span><br><span class="line">copy 0 6</span><br><span class="line"></span><br><span class="line"># check if wall to the left store in 3</span><br><span class="line">1</span><br><span class="line">copy 0 6</span><br><span class="line">copy 6 3</span><br><span class="line">2           # turn back to original direction</span><br><span class="line">copy 0 6</span><br><span class="line"></span><br><span class="line"># if no wall left, turn left until there is a wall. We follow wall on our left side</span><br><span class="line">left </span><br><span class="line">eval =</span><br><span class="line"></span><br><span class="line"># there is a wall left, check ahead</span><br><span class="line">copy 6 1</span><br><span class="line"># check right</span><br><span class="line">2</span><br><span class="line">copy 0 6</span><br><span class="line">copy 6 2</span><br><span class="line">1 </span><br><span class="line">copy 0 6</span><br><span class="line"># if wall ahead and right do a uturn</span><br><span class="line">and</span><br><span class="line">uturn</span><br><span class="line">eval !=</span><br><span class="line"></span><br><span class="line"># if wall ahead but no wall right turn right</span><br><span class="line">copy 1 3</span><br><span class="line">right</span><br><span class="line">eval !=</span><br><span class="line"></span><br><span class="line">start</span><br><span class="line">eval always </span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><center><img src="norway.jpeg" alt="NORway"><p><small>NOR-way</small></p></center><p>I thought this was quite a fun project, I certainly learnt a lot. While it may seem a little complicated, the truth is that by playing Turing Complete, you learn in a very intuitive manner. I can highly recommend it. If you want to write your own program or take a look at the code, it is all available on my <a href="https://github.com/BasedLukas/cpu_simulator">github</a>.</p>]]></content>
    
    
      
      
        
        
    <summary type="html"></summary>
        
      
    
    
    
    
    <category term="python" scheme="http://loreley.one/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Waltzing With Chance</title>
    <link href="http://loreley.one/2023-06-monte_carlo/"/>
    <id>http://loreley.one/2023-06-monte_carlo/</id>
    <published>2023-06-30T22:00:00.000Z</published>
    <updated>2025-03-31T21:57:49.722Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Suppose you were flying over the Pacific and suffered a plane crash. Luckily you survived the crash and are now stranded on a deserted island. Unfortunately, you struck your head quite badly and can no longer recall the value for pi. All you have with you is a short stick, a stone and your wits to guide you. Naturally you are concerned with the most pressing problem, viz. calculating the value of pi, which you have forgotten. How can you go about doing so?<br>Luckily for you, there exists a solution to this problem – the Monte Carlo simulation.</p><h2 id="The-Setup"><a href="#The-Setup" class="headerlink" title="The Setup"></a>The Setup</h2><p>Lets start by creating a square with sides the length of the stick “r” in the sand. Next create a circle with a radius of “r”. We can make the following statements;</p><p>The area of the circle &#x3D;  <code>Π × r²</code></p><p>The area of the square &#x3D;  <code>r²</code></p><p>Thus;</p><p>area of the circle &#x2F; area of the square &#x3D;</p><p><code>Π × r² / r²  = Π</code></p><p>All we have to do is calculate the area of the circle and the square and we can calculate pi. Unfortunately, that is quite difficult to do. Cue the Monte Carlo simulation.</p><h2 id="The-Simulation"><a href="#The-Simulation" class="headerlink" title="The Simulation"></a>The Simulation</h2><center><img src="setup.png" alt="setup"> </center> <p>Steps:</p><ul><li>Take the stone</li><li>Throw it up</li><li>Each time the stone lands make a note of whether it landed in the circle or square.</li></ul><p>Suppose you did this a few thousand times. Your final results would look something like this;</p><p>circle &#x3D;  <code>1591</code><br>square &#x3D;  <code>491</code></p><p>You can use the number of times that the stone fell inside the shape as a proxy for the area of the shape. This is the heart of a Monte Carlo simulation – using a random process to estimate some value. You can now calculate pi by simply dividing the one by the other. </p><p>To clarify, what we are doing here is estimating the area of a shape. This works because the probability that the stone will fall inside the shape is equal to the area of the shape.</p><h2 id="Simulation-in-Python"><a href="#Simulation-in-Python" class="headerlink" title="Simulation in Python"></a>Simulation in Python</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of points that landed in the circle or square</span></span><br><span class="line">in_circle = <span class="number">0</span></span><br><span class="line">in_square = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of iterations</span></span><br><span class="line">iterations = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># the radius of the circle and side of the square</span></span><br><span class="line">r = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">    <span class="comment"># randomly select 2 points between 0-20</span></span><br><span class="line">    x = random.uniform(<span class="number">0</span>, <span class="number">20</span>)</span><br><span class="line">    y = random.uniform(<span class="number">0</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># check if point (x,y) is in square (x &lt; r and y &lt; r) (bottom left corner of square is at the origin)</span></span><br><span class="line">    <span class="keyword">if</span> x &lt; r <span class="keyword">and</span> y &lt; r:</span><br><span class="line">        in_square += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate the distance between point(x,y) and center of circle (r,r)</span></span><br><span class="line">    distance = math.sqrt((r - x)**<span class="number">2</span> + (r - y)**<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># check if point (x, y) is in circle.</span></span><br><span class="line">    <span class="keyword">if</span> distance &lt; r:</span><br><span class="line">        in_circle += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            pi = in_circle / in_square</span><br><span class="line">        <span class="keyword">except</span> ZeroDivisionError:</span><br><span class="line">            pi = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Estimated value of pi after&#x27;</span>,i,<span class="string">&#x27;iterations is&#x27;</span>,pi)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Estimated value of pi after 0 iterations is 0</span><br><span class="line">Estimated value of pi after 1000 iterations is 2.7627737226277373</span><br><span class="line">Estimated value of pi after 2000 iterations is 2.911985018726592</span><br><span class="line">Estimated value of pi after 3000 iterations is 2.8870967741935485</span><br><span class="line">Estimated value of pi after 4000 iterations is 2.890334572490706</span><br><span class="line">Estimated value of pi after 5000 iterations is 2.951367781155015</span><br><span class="line">Estimated value of pi after 6000 iterations is 2.996168582375479</span><br><span class="line">Estimated value of pi after 7000 iterations is 3.0482796892341844</span><br><span class="line">Estimated value of pi after 8000 iterations is 3.040658276863504</span><br><span class="line">Estimated value of pi after 9000 iterations is 3.0583657587548636</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">Estimated value of pi after 1999000000 iterations is 3.1414178257741354</span><br></pre></td></tr></table></figure><p>Here is a plot of the points. The points that landed in the circle are red and orange. Those that landed in the square are blue and orange, and those that landed in neither are green. (Note that it makes no difference if the circle overlaps with the square, we merely want to estimate the area of each shape.)</p><center> <img src="pi.png" alt="pi"></center><p>And now for a graph of the estimated value of pi by iteration. This graph nicely illustrates the law of large numbers. In the beginning our estimate is wildly off. Over time it converges toward pi.</p><center> <img src="estimation.png" alt="setup"></center><h2 id="Snakes-and-ladders"><a href="#Snakes-and-ladders" class="headerlink" title="Snakes and ladders"></a>Snakes and ladders</h2><p>Suppose you bet on a game of snakes and ladders against somebody. Your opponent keeps winning and you suspect him of cheating. You want to calculate the probability of him finishing the game in a certain number of moves or less (you cannot remember what his dice rolls were, only the number of turns it took him to win). In order to do this you need to create a distribution of the number of moves it takes to finish the game.</p><p>The game works as follows;</p><ul><li>The players start at position 0</li><li>Each player rolls a 6 sided die</li><li>The player moves forward by the number rolled.</li><li>If the landing square is the base of a ladder, the player is transported to the top.</li><li>If the landing square is the top of a snake, the player is transported to the bottom.</li></ul><p>Calculating the distribution of the number of rolls it takes to complete the game could be quite complex. (This is called a Markov chain and can be solved algebraically). Instead we can simulate the game by randomly generating dice rolls and counting how many rolls it takes to complete the game. Doing this multiple times gives us the distribution.</p><h2 id="Simulation-in-Python-1"><a href="#Simulation-in-Python-1" class="headerlink" title="Simulation in Python"></a>Simulation in Python</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#Number of iterations to simulate</span></span><br><span class="line">iterations = <span class="number">100000</span></span><br><span class="line"></span><br><span class="line">game = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">51</span>)]</span><br><span class="line"><span class="comment">#ladders</span></span><br><span class="line">game[<span class="number">2</span>] = <span class="number">15</span></span><br><span class="line">game[<span class="number">5</span>] = <span class="number">17</span></span><br><span class="line">game[<span class="number">9</span>] = <span class="number">27</span></span><br><span class="line">game[<span class="number">17</span>] = <span class="number">41</span></span><br><span class="line">game[<span class="number">25</span>] = <span class="number">35</span></span><br><span class="line">game[<span class="number">34</span>] = <span class="number">48</span></span><br><span class="line"><span class="comment">#snakes</span></span><br><span class="line">game[<span class="number">33</span>] = <span class="number">20</span></span><br><span class="line">game[<span class="number">30</span>] = <span class="number">10</span></span><br><span class="line">game[<span class="number">20</span>] = <span class="number">1</span></span><br><span class="line">game[<span class="number">49</span>] = <span class="number">36</span></span><br><span class="line">game[<span class="number">18</span>] = <span class="number">8</span></span><br><span class="line">game[<span class="number">40</span>] = <span class="number">6</span></span><br><span class="line">game[<span class="number">26</span>] = <span class="number">19</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># the number of rolls it takes to win the game</span></span><br><span class="line">rolls = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">simulate_game</span>():</span><br><span class="line">    <span class="comment"># start at square 0</span></span><br><span class="line">    player1 = <span class="number">0</span></span><br><span class="line">    number_of_rolls = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># simulate a roll of the die</span></span><br><span class="line">        roll = random.randint(<span class="number">1</span>,<span class="number">6</span>)</span><br><span class="line">        <span class="comment"># count how many rolls the player has taken</span></span><br><span class="line">        number_of_rolls += <span class="number">1</span></span><br><span class="line">        <span class="comment"># move forward by the number rolled</span></span><br><span class="line">        player1 += roll</span><br><span class="line">        <span class="comment"># Stop once the player reaches square 50</span></span><br><span class="line">        <span class="keyword">if</span> player1 &gt;= <span class="number">50</span>:</span><br><span class="line">            <span class="keyword">return</span> number_of_rolls</span><br><span class="line">        <span class="comment"># if the player lands on a snake or ladder, move accordingly</span></span><br><span class="line">        player1 = game[player1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">    rolls.append(simulate_game())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#plot distribution of rolls</span></span><br><span class="line">plt.hist(rolls, bins=<span class="number">100</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><center> <img src="results.png" alt="results"></center><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Monte Carlo simulations are a simple but powerful tool for estimating unknown values. They are especially helpful if you don’t know probability theory (like me) and just want to know the odds of some event occurring. <a href="https://library.lanl.gov/cgi-bin/getfile?00326866.pdf">This article</a> (PDF) talks about how the first Monte Carlo simulations were used in the Manhattan project. If you would like to learn more about Markov chains, <a href="https://math.libretexts.org/Bookshelves/Applied_Mathematics/Applied_Finite_Mathematics_%28Sekhon_and_Bloom%29/10%3A_Markov_Chains/10.01%3A_Introduction_to_Markov_Chains">this article</a> is a good place to start. Creating simple simulations in python is relatively straightforward and fun.<br>I hope you get rescued from that island soon!</p>]]></content>
    
    
      
      
        
        
    <summary type="html"></summary>
        
      
    
    
    
    
    <category term="python" scheme="http://loreley.one/tags/python/"/>
    
    <category term="probability" scheme="http://loreley.one/tags/probability/"/>
    
  </entry>
  
  <entry>
    <title>Text Vectorization</title>
    <link href="http://loreley.one/2023-03-embeddings/"/>
    <id>http://loreley.one/2023-03-embeddings/</id>
    <published>2023-03-21T23:00:00.000Z</published>
    <updated>2025-03-31T21:57:49.719Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction-to-Embeddings"><a href="#Introduction-to-Embeddings" class="headerlink" title="Introduction to Embeddings"></a>Introduction to Embeddings</h2><p>Embeddings play a crucial role in natural language processing (NLP) and text analysis. Simply put, word embeddings represent words or phrases as vectors, which are lists of numbers. These vectors help encode the meaning of words so that similar words or phrases have closer vector representations. For example, the sentences “The cat quickly climbed the tree” and “The feline swiftly ascended the tree” have different words but similar meanings. Embeddings allow us to capture this similarity in meaning by placing these phrases close together in the embedding space. Embeddings make it more efficient to perform machine learning on large batches of text. By translating high-dimensional data (text) into a lower-dimensional space (vectors), embeddings efficiently capture the semantics&#x2F;meaning of inputs, which can be useful for tasks such as text search.</p><h2 id="An-Example"><a href="#An-Example" class="headerlink" title="An Example"></a>An Example</h2><p>Let’s consider a simple example of using vectors to cluster movies based on their characteristics. Imagine arranging a set of movies on a one-dimensional number line, where movies that are more closely related are placed closer together. This arrangement might represent movies based on their appeal to different age groups, such as children versus adults. -1 would represent a children’s movie and 1 would represent an adult movie. Each movie could be given a score based on its audience’s age group.  </p><p>However, there are other aspects, like genre, that can also contribute to the similarity between movies. To capture this, we can extend the arrangement to a two-dimensional space, where one dimension represents the age group and the other represents the genre. For instance, a movie could be represented as a vector (0.3, 0.2), where 0.3 corresponds to the age group, and 0.2 corresponds to the genre. This embedding helps us identify and group movies based on their appeal to different age groups and genres.</p><center><img src="embedding2d.jpg" alt="embedding2d"><p><small><a href="https://developers.google.com/machine-learning/crash-course/embeddings/motivation-from-collaborative-filtering">source</a></small></p></center><h2 id="Generalising-to-Higher-Dimensions"><a href="#Generalising-to-Higher-Dimensions" class="headerlink" title="Generalising to Higher Dimensions"></a>Generalising to Higher Dimensions</h2><p>As we’ve seen with the simple movie clustering example, we can represent data points in multi-dimensional spaces to capture various characteristics. The same concept can be applied to more complex data, such as geographical locations or even natural language text.</p><center><img src="linear-relationships.jpg" alt="linear-relationships"><p><small><a href="https://developers.google.com/machine-learning/crash-course/embeddings/translating-to-a-lower-dimensional-space">source</a></small></p></center><p>In the image above, capital cities are positioned close to their respective countries. In this space, not only are capital cities near their countries, but similar countries are also close to one another but along a different dimension. This arrangement effectively captures the relationships between countries and their capitals.</p><p>Generalising this concept to even higher dimensions allows us to represent more complex information, such as text. In this case, each dimension represents a different concept or aspect of the text, which enables us to encode an entire paragraph or a block of text as a single vector. By representing text in this manner, we can capture the underlying semantic meaning and relationships between words, phrases, or even entire paragraphs.</p><h2 id="Using-Vectors"><a href="#Using-Vectors" class="headerlink" title="Using Vectors"></a>Using Vectors</h2><p>To determine if two vectors are close to one another, we can use the cosine similarity. The cosine similarity measures the cosine of the angle between the two vectors, resulting in a value between -1 and 1. A value closer to 1 indicates a higher similarity, while a value closer to -1 indicates a lower similarity.</p><p>One example of using vectors in text analysis is classifying reviews as positive or negative. In this case, we can represent each review as a vector and train a machine learning model to classify them based on their vector representations. The model could learn to classify reviews as positive or negative based on the similarity between the review vectors and vectors representing positive or negative sentiment.</p><p>Another example is searching within a large body of text. In this scenario, we can break the text into smaller chunks or segments, each represented as a vector. When a user submits a search query, we convert the query into a vector in the same embedding space. To find the most relevant match, we measure the similarity between the search query vector and the vectors representing the chunks of text using cosine similarity. The chunk with the highest similarity to the search query vector is considered the best match for the user’s query.</p><h2 id="Trying-it-out"><a href="#Trying-it-out" class="headerlink" title="Trying it out"></a>Trying it out</h2><p>Generating or computing word vectors involves training a machine learning model on a large corpus of text. The model learns to represent words or phrases as vectors based on the context in which they appear, capturing semantic meaning and relationships between words. Take a look at this example of 3 vectors constructed using the OpenAI Ada-2 model (input 2 says ”I really like running” in Dutch). </p><center><img src="python_embeddings.png" alt="python embeddings"></center><p>When we compute the cosine similarity between them this is what we get;</p><center><img src="python_embeddings2.png" alt="python embeddings"></center><p>The two sentences about running are very close together, even though the languages are different. The cat sentence is farther apart. Now look at what happens if we compare the sentence “I enjoy jogging” with “I do not enjoy jogging”.</p><center><img src="python_embeddings3.png" alt="python embeddings"></center><p>They are really close together! Closer than the English – Dutch pair. Can you figure out why?</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>In this article we have learned what embeddings are, and seen how they can be used for various natural language processing tasks. If you found this interesting you can read more in depth <a href="http://www.offconvex.org/2015/12/12/word-embeddings-1/">here</a> or <a href="https://p.migdal.pl/2017/01/06/king-man-woman-queen-why.html/">here</a>. </p>]]></content>
    
    
      
      
        
        
    <summary type="html"></summary>
        
      
    
    
    
    
    <category term="python" scheme="http://loreley.one/tags/python/"/>
    
    <category term="NLP" scheme="http://loreley.one/tags/NLP/"/>
    
    <category term="models" scheme="http://loreley.one/tags/models/"/>
    
  </entry>
  
  <entry>
    <title>Therapeutic Plasma Exchange</title>
    <link href="http://loreley.one/2022-06-tpe/"/>
    <id>http://loreley.one/2022-06-tpe/</id>
    <published>2022-06-01T22:00:00.000Z</published>
    <updated>2025-03-31T21:57:49.755Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Why-do-we-age"><a href="#1-Why-do-we-age" class="headerlink" title="1. Why do we age?"></a>1. Why do we age?</h2><p>When you are injured your body can heal itself. So why do people age? Why can’t they continually repair themselves and remain eternally youthful? While it’s generally agreed that aging is the effect of systemic degradation on the body’s ability to repair itself, what causes this degradation is less clear. To answer this let’s look at parabiosis.</p><h4 id="A-background-on-parabiosis"><a href="#A-background-on-parabiosis" class="headerlink" title="A background on parabiosis"></a>A background on parabiosis</h4><p>Parabiosis is a surgical procedure where two animals’ circulatory systems are stitched together. Why would you want to do that? Well, if you attach a younger mouse to an older one (heterochronic parabiosis) the older mouse grows younger, while the younger mouse actually ages! Importantly, the cells of the older mice actually regenerate - they are able to repair themselves, something older cells typically can’t do.</p><p>The above-mentioned experiment was conducted by the Conboys, a couple researching aging at Berkley, back in 2005. To quote from their paper:</p><blockquote><p>   “Our experiments suggest… … that the systemic environment of a young animal is one that promotes successful regeneration, whereas that of an older animal either fails to promote or actively inhibits successful tissue regeneration… …Our studies also demonstrate that the decline of tissue regenerative potential with age can be reversed through the modulation of systemic factors, suggesting that tissues specific stem and progenitor cells retain much of their intrinsic proliferative potential even when old, but that age-related changes in the systemic environment and niche in which progenitor cells reside preclude full activation of these cells for productive tissue regeneration.” <a href="https://www.nature.com/articles/nature03260">https://www.nature.com/articles/nature03260</a></p></blockquote><p>The fact that an older mouse’s tissue can regenerate is important. It is a clear indication that the mouse’s cells retain the ability to regenerate, given the correct environment. Furthermore, young mice, given a bad environment suddenly grow old and lose some of their ability to repair themselves. This means that it’s something environmental (systemic milieu) that’s causing aging to happen.</p><h4 id="Isolating-the-cause"><a href="#Isolating-the-cause" class="headerlink" title="Isolating the cause"></a>Isolating the cause</h4><p>The problem with this experiment is that parabiosis is complex. There are many factors that could be responsible for influencing the systemic milieu other than just the blood (shared organs etc). In order to verify that it is the blood, and not something else causing the regeneration, we need to conduct a better experiment.</p><h2 id="2-An-improved-experiment"><a href="#2-An-improved-experiment" class="headerlink" title="2. An improved experiment"></a>2. An improved experiment</h2><p>The Conboys developed a new system. One that would allow them to exchange blood between two mice without having to stitch them together. This isn’t as easy as it sounds.</p><blockquote><p>“We developed a blood exchange system where animals are connected and disconnected at will, removing the influence of shared organs, adaptation to being joined and so on.” <a href="https://doi.org/10.1038/ncomms13363">https://doi.org/10.1038/ncomms13363</a></p></blockquote><p>Now it’s possible to see what happens when we give older mice blood transfusions from young mice, and vice versa. Do the effects seen in the previous experiment still take place? Let’s look at the effect on 3 different types of mouse cells when they received a heterochronous blood transfusion.</p><h4 id="Muscle-cells"><a href="#Muscle-cells" class="headerlink" title="Muscle cells:"></a>Muscle cells:</h4><blockquote><p>“These data extrapolate the findings obtained with heterochronic parabiosis, and establish that the beneficial effects of young blood for the regeneration of old muscle take place right away and without the contribution of young organ systems”</p></blockquote><p>Old muscle cells regenerate when supplied with young blood.</p><h4 id="Brain-Cells"><a href="#Brain-Cells" class="headerlink" title="Brain Cells:"></a>Brain Cells:</h4><blockquote><p>“One exchange of heterochronic blood severely decreased hippocampal neurogenesis in young mice, and surprisingly, there was no significant positive effect in the old mice that had been exchanged with young blood. Of note, these were the same old animals that showed improvement in muscle regeneration… …Muscle injury after blood exchange might add to the magnitude of the negative effects of old blood on young neurogenesis, and even without muscle injury, young hippocampal neurogenesis quickly declines after one old blood exchange.”</p></blockquote><p>Old blood damages young brain cells, but young blood doesn’t seem to improve old brain cells.</p><h4 id="Liver-cells"><a href="#Liver-cells" class="headerlink" title="Liver cells:"></a>Liver cells:</h4><blockquote><p>“…interestingly, transfusion with young blood somewhat reduced old liver adiposity, (while there was no significant increase in young liver adiposity). These results demonstrate that heterochronic blood exchange and heterochronic parabiosis yield similar enhancement of old hepatogenesis and decline of young hepatogenesis…. …Additionally, the fibrotic regions and adiposity rapidly decline in old livers after the exposure to young blood. Such effects manifest after just a single procedure of blood exchange and in the absence of the influences from heterochronic organ systems.”</p></blockquote><center><img src="liver_adiposity.webp" alt="liver_adiposity"><p><small>Liver Adiposity showing the effects of different blood on old and young mice.</small></p></center><h4 id="To-summarize"><a href="#To-summarize" class="headerlink" title="To summarize:"></a>To summarize:</h4><ul><li>The effects of parabiosis hold even with only a single blood transfusion.</li><li>Young blood appears to have a positive impact on old mice.</li><li>Old blood appears to have a negative impact on young mice.</li><li>Regeneration in old mice could be due to positive factors in the young blood or due to negative factors in the old blood being diluted.</li></ul><h2 id="3-It’s-not-the-blood"><a href="#3-It’s-not-the-blood" class="headerlink" title="3. It’s not the blood"></a>3. It’s not the blood</h2><p>At this point, it’s important not to get carried away. The media immediately focused on the vampirism aspect and startups touted transfusion treatments, generating hysterical headlines and an FDA-issued <a href="https://www.fda.gov/news-events/press-announcements/statement-fda-commissioner-scott-gottlieb-md-and-director-fdas-center-biologics-evaluation-and-0">warning</a>. </p><h4 id="It’s-the-old-blood-we-should-focus-on"><a href="#It’s-the-old-blood-we-should-focus-on" class="headerlink" title="It’s the old blood we should focus on"></a>It’s the old blood we should focus on</h4><p>Maybe there’s nothing special about young blood. Maybe there’s something in old blood that’s inhibiting cell regeneration. When you switch blood between two mice, what you are actually doing is removing the harmful blood from the old mouse and giving it to the young mouse. This would explain why the younger mouse ages! And it means that simply removing harmful factors from old blood could cause regeneration!</p><blockquote><p>   “It was not formally established that young blood is necessary for this multi-tissue rejuvenation. …we replaced half of the plasma in mice with saline containing 5% albumin (terming it a “neutral” age blood exchange, NBE) thus diluting the plasma factors and replenishing the albumin that would be diminished if only saline was used.”</p></blockquote><blockquote><p>   “Our data demonstrate that a single NBE suffices to meet or exceed the rejuvenative effects of enhancing muscle repair, reducing liver adiposity and fibrosis, and increasing hippocampal neurogenesis in old mice, all the key outcomes seen after blood heterochronicity.” <a href="https://doi.org/10.18632/aging.103418">https://doi.org/10.18632/aging.103418</a></p></blockquote><p>They removed some of the mouse’s plasma (a component of blood), and replaced it with an albumin solution and still got positive results! There’s no need for young blood, all you need to do is remove negative factors from the old blood!</p><blockquote><p>“Summarily, these results establish broad tissues rejuvenation by a single replacement of old blood plasma with physiologic fluid: muscle repair was improved, fibrosis was attenuated, and inhibition of myogenic proliferation was switched to enhancement; liver adiposity and fibrosis were reduced; and hippocampal neurogenesis was increased. This rejuvenation is similar to (liver) or is stronger than (muscle and brain) that seen after heterochronic parabiosis or blood exchange.” </p></blockquote><blockquote><p>“These findings are most consistent with the conclusion that the age-altered systemic milieu inhibits the health and repair of multiple tissues in the old mice, and also exerts a dominant progeric effect on the young partners in parabiosis or blood exchange.”</p></blockquote><h4 id="Dilution-of-old-blood-causes-rejuvenation"><a href="#Dilution-of-old-blood-causes-rejuvenation" class="headerlink" title="Dilution of old blood causes rejuvenation"></a>Dilution of old blood causes rejuvenation</h4><p>So actually, just replacing the plasma from old blood with an albumin solution seems to provide all the benefits of young blood! It seems that plasma factors in the blood of old animals are somehow inhibiting cell regeneration – causing aging. Once these harmful factors are removed from the blood, the cells are able to regenerate, making them young again!</p><h2 id="4-Treatments-in-humans"><a href="#4-Treatments-in-humans" class="headerlink" title="4. Treatments in humans"></a>4. Treatments in humans</h2><p>This is all good and well, but I’m no mouse. How can we benefit? Well, the good news is that a treatment called TPE already exists. TPE; therapeutic plasma exchange is similar to the NBE that was tried in mice. It’s used to treat various conditions and is FDA approved.</p><p>Here’s how it works. Blood is drawn, and the plasma fraction separated and removed. The blood cells are then resuspended in an albumin solution and returned to the patient. This allows us to achieve the plasma dilution necessary to remove the harmful factors from the blood. All that’s being done is that the blood is being “cleaned” of the harmful factors in the plasma that have been shown to contribute to aging, no young blood is needed at all.</p><center><img src="effect_of_tpe.webp" alt="effect_of_tpe"><p><small>Effects of TPE on the blood. https://doi.org/10.1016/j.transci.2021.103162 </small></p></center><h4 id="Moving-forward"><a href="#Moving-forward" class="headerlink" title="Moving forward"></a>Moving forward</h4><p>Currently, trials are underway to better understand the effects of TPE. One interesting insight we already have is that not only does TPE reduce the levels of certain factors in the blood but it also raises the levels of other proteins such as EPO (erythropoietin). This suggests that the factors removed from the blood have some sort of inhibitory effect and that once they’re removed certain proteins are better expressed! </p><center><img src="protein_levels.webp" alt="protein_levels"><p><small>https://doi.org/10.1016/j.transci.2021.103162 </small></p></center><blockquote><p>   “Because repositioning TPE as a rejuvenative therapeutic is a relatively new concept, there are many unexplored questions regarding its potential and utility. Our recent 2020 studies demonstrated rejuvenation of three key tissues –muscle, liver and brain, as well as improved cognition and shortmemory in old mice – but other areas of health that decline withage are yet to be explored. Furthermore, it is unknown how long theserejuvenative effects persist. The health of the studied tissues is inter-estingly closer to the young than the old mammal (e.g. robustly reju-venated), but it is unknown if the rate of tissue health decay will be akinto a middle-aged mouse or if it will decline at a different rate. Perhaps,TPE will continue to stave off tissue decline for a longer period.Aging results in a near-endless list of systemic changes on tissue,cellular and molecular levels, and multiple methods of therapeutics willbe required to address these alterations. More research is clearly needed to develop and explore the applications of rejuvenative plasmapheresis alone or in combination with other therapeutics” doi.org&#x2F;10.1016&#x2F;j.transci.2021.103162</p></blockquote><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>We will have to await the results of further trials to see exactly how much TPE helps. But the results seem pretty robust thus far. The real advantage of this method is that it doesn’t require developing a new drug, it works by removing the harmful elements from the body. This is a major advantage in terms of getting treatments approved and ensuring their safety.</p><p>Let me know what you think, and tell me if I’ve missed something or made any mistakes. This is my attempt to summarize the research, but I certainly could’ve gotten something wrong.</p><p><a href="https://neo.life/2021/06/perspective-therapeutic-plasma-exchange-the-future-of-aging/">https://neo.life/2021/06/perspective-therapeutic-plasma-exchange-the-future-of-aging/ </a><br><a href="https://www.nature.com/articles/nature03260">https://www.nature.com/articles/nature03260 </a><br><a href="http://doi.org/10.1038/ncomms13363">http://doi.org/10.1038/ncomms13363 </a><br><a href="https://www.aging-us.com/article/103418/text">https://www.aging-us.com/article/103418/text </a><br><a href="https://doi.org/10.1016/j.transci.2021.103162">https://doi.org/10.1016/j.transci.2021.103162 </a></p>]]></content>
    
    
      
      
        
        
    <summary type="html"></summary>
        
      
    
    
    
    
    <category term="longevity" scheme="http://loreley.one/tags/longevity/"/>
    
  </entry>
  
</feed>
